{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis paper\n",
    "# import libraries\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as _stats\n",
    "from functools import reduce\n",
    "from pipeline.analysis import *\n",
    "from pipeline.utils import validate\n",
    "from pipeline import *\n",
    "import logging\n",
    "import networkx as nx\n",
    "import glob\n",
    "from scipy.stats import sem as sem\n",
    "from matplotlib import colormaps\n",
    "import sys\n",
    "# sys.path.insert(1, \"/home/anna/Documents/code/python/pipeline\")\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "# warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "print(BSS.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_perts_file(\n",
    "    val_dict,\n",
    "    file_path: str,\n",
    "    eng: Optional[str] = None,\n",
    "    analysis_string: Optional[str] = None,\n",
    "    method: Optional[str] = None,\n",
    "):\n",
    "    val_dict = validate.dictionary(val_dict)\n",
    "\n",
    "    if not method:\n",
    "        method = \"None\"\n",
    "\n",
    "    with open(f\"{file_path}.csv\", \"w\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"lig_0\", \"lig_1\", \"freenrg\", \"error\",\n",
    "                        \"engine\", \"analysis\", \"method\"])\n",
    "\n",
    "        for key, value in val_dict.items():\n",
    "            writer.writerow([key.split(\"~\")[0], key.split(\n",
    "                \"~\")[1], value[0], value[1], eng, analysis_string, method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the analysis method to use\n",
    "ana_dicts = {\"plain\": {\n",
    "    \"estimator\": \"MBAR\",\n",
    "    \"method\": \"alchemlyb\",\n",
    "    \"check overlap\": True,\n",
    "    \"try pickle\": True,\n",
    "    \"save pickle\": True,\n",
    "    \"auto equilibration\": False,\n",
    "    \"statistical inefficiency\": False,\n",
    "    \"truncate lower\": 0,\n",
    "    \"truncate upper\": 100,\n",
    "    \"name\": None,\n",
    "},\n",
    "    \"subsampling\": {\n",
    "    \"estimator\": \"MBAR\",\n",
    "    \"method\": \"alchemlyb\",\n",
    "    \"check overlap\": True,\n",
    "    \"try pickle\": True,\n",
    "    \"save pickle\": True,\n",
    "    \"auto equilibration\": False,\n",
    "    \"statistical inefficiency\": True,\n",
    "    \"truncate lower\": 0,\n",
    "    \"truncate upper\": 100,\n",
    "    \"name\": None,\n",
    "},\n",
    "#     \"1ns\": {\n",
    "#     \"estimator\": \"MBAR\",\n",
    "#     \"method\": \"alchemlyb\",\n",
    "#     \"check overlap\": True,\n",
    "#     \"try pickle\": True,\n",
    "#     \"save pickle\": True,\n",
    "#     \"auto equilibration\": False,\n",
    "#     \"statistical inefficiency\": True,\n",
    "#     \"truncate lower\": 0,\n",
    "#     \"truncate upper\": 25,\n",
    "#     \"name\": None,\n",
    "# },\n",
    "#     \"2ns\": {\n",
    "#     \"estimator\": \"MBAR\",\n",
    "#     \"method\": \"alchemlyb\",\n",
    "#     \"check overlap\": True,\n",
    "#     \"try pickle\": True,\n",
    "#     \"save pickle\": True,\n",
    "#     \"auto equilibration\": False,\n",
    "#     \"statistical inefficiency\": True,\n",
    "#     \"truncate lower\": 0,\n",
    "#     \"truncate upper\": 50,\n",
    "#     \"name\": None,\n",
    "# },\n",
    "#     \"3ns\": {\n",
    "#     \"estimator\": \"MBAR\",\n",
    "#     \"method\": \"alchemlyb\",\n",
    "#     \"check overlap\": True,\n",
    "#     \"try pickle\": True,\n",
    "#     \"save pickle\": True,\n",
    "#     \"auto equilibration\": False,\n",
    "#     \"statistical inefficiency\": True,\n",
    "#     \"truncate lower\": 0,\n",
    "#     \"truncate upper\": 75,\n",
    "#     \"name\": None,\n",
    "# },\n",
    "#     \"autoeq\": {\n",
    "#     \"estimator\": \"MBAR\",\n",
    "#     \"method\": \"alchemlyb\",\n",
    "#     \"check overlap\": True,\n",
    "#     \"try pickle\": True,\n",
    "#     \"save pickle\": True,\n",
    "#     \"auto equilibration\": True,\n",
    "#     \"statistical inefficiency\": True,\n",
    "#     \"truncate lower\": 0,\n",
    "#     \"truncate upper\": 100,\n",
    "#     \"name\": None,\n",
    "# },\n",
    "    # \"TI\": {\n",
    "    # \"estimator\": \"TI\",\n",
    "    # \"method\": \"alchemlyb\",\n",
    "    # \"check overlap\": True,\n",
    "    # \"try pickle\": True,\n",
    "    # \"save pickle\": True,\n",
    "    # \"auto equilibration\": False,\n",
    "    # \"statistical inefficiency\": True,\n",
    "    # \"truncate lower\": 0,\n",
    "    # \"truncate upper\": 100,\n",
    "    # \"name\": None,\n",
    "# },\n",
    "#     \"single_0\": {\n",
    "#     \"estimator\": \"MBAR\",\n",
    "#     \"method\": \"alchemlyb\",\n",
    "#     \"check overlap\": True,\n",
    "#     \"try pickle\": True,\n",
    "#     \"save pickle\": True,\n",
    "#     \"auto equilibration\": False,\n",
    "#     \"statistical inefficiency\": False,\n",
    "#     \"truncate lower\": 0,\n",
    "#     \"truncate upper\": 100,\n",
    "#     \"name\": None,\n",
    "# },\n",
    "#     \"single_1\": {\n",
    "#     \"estimator\": \"MBAR\",\n",
    "#     \"method\": \"alchemlyb\",\n",
    "#     \"check overlap\": True,\n",
    "#     \"try pickle\": True,\n",
    "#     \"save pickle\": True,\n",
    "#     \"auto equilibration\": False,\n",
    "#     \"statistical inefficiency\": False,\n",
    "#     \"truncate lower\": 0,\n",
    "#     \"truncate upper\": 100,\n",
    "#     \"name\": None,\n",
    "# },\n",
    "#     \"single_2\": {\n",
    "#     \"estimator\": \"MBAR\",\n",
    "#     \"method\": \"alchemlyb\",\n",
    "#     \"check overlap\": True,\n",
    "#     \"try pickle\": True,\n",
    "#     \"save pickle\": True,\n",
    "#     \"auto equilibration\": False,\n",
    "#     \"statistical inefficiency\": False,\n",
    "#     \"truncate lower\": 0,\n",
    "#     \"truncate upper\": 100,\n",
    "#     \"name\": None,\n",
    "# }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables\n",
    "network = \"lomap\"  # lomap rbfenn combined\n",
    "\n",
    "prot_dict_name = {\"tyk2\":\"TYK2\", \"mcl1\":\"MCL1\", \"p38\":\"P38α\", \"syk\":\"SYK\", \"hif2a\":\"HIF2A\", \"cmet\":\"CMET\"}\n",
    "eng_dict_name = {\"AMBER\":\"AMBER22\",\"SOMD\":\"SOMD1\",\"GROMACS\":\"GROMACS23\"}\n",
    "\n",
    "# all the options\n",
    "ana_obj_dict = {}\n",
    "\n",
    "for protein in [\"tyk2\", \"mcl1\", \"p38\", \"syk\", \"hif2a\", \"cmet\"]:\n",
    "\n",
    "    ana_obj_dict[protein] = {}\n",
    "\n",
    "    for ana_dict in ana_dicts:\n",
    "        ana_prot = analysis_protocol(ana_dicts[ana_dict])\n",
    "        print(protein, ana_dict)\n",
    "\n",
    "        if protein == \"syk\" or protein == \"cmet\":\n",
    "            main_dir = f\"/backup/{protein}/neutral\"\n",
    "        else:\n",
    "            main_dir = f\"/backup/{protein}\"\n",
    "\n",
    "        bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "\n",
    "        # if need size of protein\n",
    "        try:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.gro\", f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.top\"])[0]\n",
    "        except:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.prm7\", f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.rst7\"])[0]\n",
    "\n",
    "        print(f\"no of residues in the protein: {prot.nResidues()}\")\n",
    "\n",
    "        # choose location for the files\n",
    "        if protein == \"syk\" or protein == \"cmet\" or protein == \"hif2a\":\n",
    "            # the lomap network\n",
    "            net_file = f\"{main_dir}/execution_model/network_all.dat\"\n",
    "        else:\n",
    "            net_file = f\"{main_dir}/execution_model/network_{network}.dat\"\n",
    "\n",
    "        exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "        output_folder = f\"{main_dir}/outputs_extracted\"\n",
    "\n",
    "        # prot_file = f\"{main_dir}/execution_model/protocol.dat\" # no protocol used , name added after if needed\n",
    "        pipeline_prot = pipeline_protocol(auto_validate=True)\n",
    "        # pipeline_prot.name(\"\")\n",
    "\n",
    "        # initialise the network object\n",
    "        all_analysis_object = analysis_network(\n",
    "            output_folder,\n",
    "            exp_file=exp_file,\n",
    "            net_file=net_file,\n",
    "            analysis_prot=ana_prot,\n",
    "            method=pipeline_prot.name(),  # if the protocol had a name\n",
    "            engines=pipeline_prot.engines(),\n",
    "        )\n",
    "\n",
    "        # compute\n",
    "        all_analysis_object.compute_results()\n",
    "\n",
    "        if ana_dict == \"single\":\n",
    "            all_analysis_object.file_ext = all_analysis_object.file_ext+f\"_{ana_dict}\"\n",
    "            \n",
    "        # add ligands folder\n",
    "        if os.path.isdir(f\"{bench_folder}/inputs/{protein}/ligands\"):\n",
    "            all_analysis_object.add_ligands_folder(\n",
    "                f\"{bench_folder}/inputs/{protein}/ligands\")\n",
    "        else:\n",
    "            all_analysis_object.add_ligands_folder(\n",
    "                f\"{bench_folder}/inputs/{protein}/ligands_neutral\")\n",
    "\n",
    "        ana_obj_dict[protein][ana_dict] = all_analysis_object\n",
    "\n",
    "print(ana_obj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check maximum possible accuracy\n",
    "r2_dict = {}\n",
    "r2_error_dict = {}\n",
    "for prot in ana_obj_dict.keys():\n",
    "    r2_dict[prot] = {}\n",
    "    r2_error_dict[prot] = {}\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "    print(prot, len(ana_obj.ligands))\n",
    "    print(\"max\", max(ana_obj.exper_val_dict.values())[0], \"min\",\n",
    "          min(ana_obj.exper_val_dict.values())[0], \"range\", \n",
    "          max(ana_obj.exper_val_dict.values())[0]-min(ana_obj.exper_val_dict.values())[0])\n",
    "    avg = np.mean([val[1] for val in ana_obj.exper_val_dict.values()])\n",
    "    std = np.std([val[0] for val in ana_obj.exper_val_dict.values()])\n",
    "    print(\"mean of error\", avg, \"std of val\", std)\n",
    "    # experimental uncertainty is std of measurement error\n",
    "    # max is measurement error / std dev of the affinity , squared\n",
    "    # tyk2 mcl1 Ki 0.44\n",
    "    # others IC50 0.75\n",
    "    r2max = 1 - (avg / std)**2\n",
    "    print(r2max)\n",
    "    r2_dict[prot][\"maximum\"] = r2max\n",
    "    r2_error_dict[prot][\"maximum\"] = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude outliers\n",
    "threshold = 10\n",
    "for prot in ana_obj_dict.keys():\n",
    "\n",
    "    for name in ana_dicts.keys():\n",
    "        print(prot, name)\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            ana_obj.file_ext = ana_obj.file_ext + f\"_outliers{threshold}removed\"\n",
    "            ana_obj.remove_outliers(threshold=threshold, name=eng)\n",
    "        # print(ana_obj.file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot = \"mcl1\"\n",
    "lig = \"lig_45\"\n",
    "ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "for pert in ana_obj.perturbations:\n",
    "    if lig in pert:\n",
    "        print(pert)\n",
    "        for eng in ana_obj.engines:\n",
    "            print(eng, ana_obj.calc_pert_dict[eng][pert])\n",
    "        print(\"exp\", ana_obj.exper_pert_dict[pert])\n",
    "        ana_obj.remove_perturbations([pert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = ana_obj.calc_kendalls_rank_engines(pert_val=\"val\", recalculate=True)\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    print(\n",
    "        f\"{eng} MAE: {mae[0][eng]['experimental']:.2f} {mae[2][eng]['experimental']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "from rdkit import Chem\n",
    "\n",
    "name_dict = {}\n",
    "for prot in [\"syk\", \"hif2a\", \"cmet\"]:\n",
    "    jacs_file = f\"/home/anna/Documents/benchmark/inputs/{prot}/results_edges_5ns.csv\"\n",
    "    mols = Chem.SDMolSupplier(\n",
    "        f\"/home/anna/Documents/benchmark/inputs/{prot}/ligands.sdf\")\n",
    "    name_dict[prot] = {}\n",
    "    for mol,idx in zip(mols, range(1,len(mols)+1,1)):\n",
    "        name_dict[prot][mol.GetProp(\"_Name\")] = f\"lig_{idx}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to shroedinger results\n",
    "\n",
    "jacs_file = \"/home/anna/Documents/benchmark/inputs/jacs2015_inputs/jacs2015results.csv\"\n",
    "jacs_df = pd.read_csv(jacs_file)\n",
    "# jacs_df\n",
    "\n",
    "jacs_dict = {} # convert into a dictionary of values\n",
    "\n",
    "for prot in [\"Tyk2\", \"MCL1\", \"P38\"]:\n",
    "    jacs_dict[prot.lower()] = {}\n",
    "    for index, row in jacs_df.iterrows():\n",
    "        if row[\"system\"].upper() == prot.upper():\n",
    "            jacs_dict[prot.lower()][f\"{row['Ligand1']}~{row['Ligand2']}\"] = (row['bennett_ddG'], row['bennett_error'])\n",
    "\n",
    "for prot in [\"syk\", \"hif2a\", \"cmet\"]:\n",
    "    jacs_file = f\"/home/anna/Documents/benchmark/inputs/{prot}/results_edges_5ns.csv\"\n",
    "    jacs_df = pd.read_csv(jacs_file)\n",
    "    jacs_dict[prot.lower()] = {}\n",
    "    for index, row in jacs_df.iterrows():\n",
    "        jacs_dict[prot.lower()][f\"{name_dict[prot][row['Ligand1']]}~{name_dict[prot][row['Ligand2']]}\"] = (\n",
    "            row['FEP'], row['FEP Error'])\n",
    "\n",
    "\n",
    "# exper dict\n",
    "exper_dict_missing = {}\n",
    "fep_lig_dict = {}\n",
    "\n",
    "jacs_file = \"/home/anna/Documents/benchmark/inputs/jacs2015_inputs/jacs2015resultsdG.csv\"\n",
    "jacs_df = pd.read_csv(jacs_file, delimiter=\",\")\n",
    "\n",
    "for prot in [\"Tyk2\", \"MCL1\", \"P38\"]:\n",
    "    exper_dict_missing[prot.lower()] = {}\n",
    "    fep_lig_dict[prot.lower()] = {}\n",
    "    for index, row in jacs_df.iterrows():\n",
    "        if row[\"Systems\"].upper() == prot.upper():\n",
    "            try:\n",
    "                exper_dict_missing[prot.lower()][row['Ligand']] = (row['Exp. dG'], 0.44)\n",
    "                fep_lig_dict[prot.lower()][row['Ligand']] = (row['Pred. dG'], row['Pred. Error'])\n",
    "            except:\n",
    "                print(row['Ligand'])\n",
    "\n",
    "for prot in [\"syk\", \"hif2a\", \"cmet\"]:\n",
    "    jacs_file = f\"/home/anna/Documents/benchmark/inputs/{prot}/results_5ns.csv\"\n",
    "    jacs_df = pd.read_csv(jacs_file, delimiter=\",\")\n",
    "    exper_dict_missing[prot] = {}\n",
    "    fep_lig_dict[prot] = {}\n",
    "    for index, row in jacs_df.iterrows():\n",
    "        try:\n",
    "            exper_dict_missing[prot][name_dict[prot][row['Ligand']]] = (row['Exp. ΔG'], 0.44)\n",
    "            fep_lig_dict[prot][name_dict[prot][row['Ligand']]] = (row['Pred. ΔG'], row['Pred. Error'])\n",
    "        except:\n",
    "            print(row['Ligand'])\n",
    "     \n",
    "\n",
    "# for cinnabar files\n",
    "for prot in ana_obj_dict.keys():\n",
    "    write_perts_file(jacs_dict[prot],\n",
    "                     file_path=f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_fepplus\", # .csv\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# professa results\n",
    "prot = \"tyk2\"\n",
    "file = f\"/home/anna/Documents/benchmark/inputs/other_computed/professa/professa_{prot}_results.dat\"\n",
    "ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "df = pd.read_csv(file, delimiter=\",\")\n",
    "\n",
    "perts_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    perts_dict[f\"{row['perturbation']}\"] = (\n",
    "        float(row['ddG']), float(row['ddG_error']))\n",
    "write_perts_file(perts_dict,\n",
    "                 # .csv\n",
    "                 file_path=f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_professa\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hahn et al\n",
    "file = f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn_tyk2_kjmol.dat\"\n",
    "\n",
    "df = pd.read_csv(file, delimiter=\",\")\n",
    "\n",
    "perts_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    perts_dict[f\"{row['perturbation']}\"] = (\n",
    "        float(row['ddG']), float(row['ddG_error']))\n",
    "\n",
    "# need to convert into kcal/mol\n",
    "for key in perts_dict:\n",
    "    perts_dict[key] = (perts_dict[key][0]*0.239006,perts_dict[key][1]*0.239006)\n",
    "\n",
    "write_perts_file(perts_dict,\n",
    "                 # .csv\n",
    "                 file_path=f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_hahn\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = \"hahn\"\n",
    "\n",
    "files = [f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_{name}.csv\"] \n",
    "\n",
    "calc_diff_dict = make_dict.comp_results(\n",
    "    files\n",
    ")  # older method\n",
    "\n",
    "perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "\n",
    "if name == \"fepplus\":\n",
    "    exper_dict = exper_dict_missing[prot]\n",
    "elif name == \"hahn\":\n",
    "    exper_dict = pipeline.analysis.convert.yml_into_exper_dict(exp_file=ana_obj.exp_file, temperature=298)\n",
    "else:\n",
    "    exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "convert.cinnabar_file(\n",
    "    files,\n",
    "    exper_dict,\n",
    "    f\"/home/anna/Documents/benchmark/inputs/{prot}/cinnabar_{name}\",\n",
    "    perturbations=perts,\n",
    "    method=None,\n",
    ")\n",
    "\n",
    "# compute the per ligand for the network\n",
    "network = wrangle.FEMap(\n",
    "    f\"/home/anna/Documents/benchmark/inputs/{prot}/cinnabar_{name}.csv\")\n",
    "\n",
    "# for self plotting of per ligand\n",
    "cinnabar_calc_val_dict = make_dict.from_cinnabar_network_node(network, \"calc\")\n",
    "cinnabar_calc_pert_dict = make_dict.from_cinnabar_network_edges(network, \"calc\", perts)\n",
    "\n",
    "# normalise exper dict\n",
    "normalised_exper_dict = {}\n",
    "avg = np.mean([val[0] for val in exper_dict.values()])\n",
    "for lig in exper_dict:\n",
    "    normalised_exper_dict[lig] = (exper_dict[lig][0] - avg,exper_dict[lig][1])\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "xerr = []\n",
    "yerr = []\n",
    "for lig in ligs:\n",
    "    if not np.isnan(cinnabar_calc_val_dict[lig][0]):\n",
    "        x.append(cinnabar_calc_val_dict[lig][0])\n",
    "        xerr.append(cinnabar_calc_val_dict[lig][1])\n",
    "        y.append(normalised_exper_dict[lig][0])\n",
    "        yerr.append(normalised_exper_dict[lig][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE cinnabar tyk2 (0.7100596494567039, 0.11323365001909216, [0.4406718881317579, 0.8892374700895855])\n"
     ]
    }
   ],
   "source": [
    "# print(x,y,xerr,yerr)\n",
    "res = stats_engines.compute_stats(x=x, xerr=xerr,\n",
    "                                  y=y, yerr=yerr,\n",
    "                                  statistic=\"R2\")\n",
    "print(\"MAE cinnabar\", prot, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE tyk2 (0.9696921170470629, 0.13729152501996844, [0.7043448324660908, 1.2377697399861662])\n"
     ]
    }
   ],
   "source": [
    "exper_pert_dict = pipeline.analysis.make_dict.exper_from_perturbations(exper_dict, perts)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "xerr = []\n",
    "yerr = []\n",
    "for lig in perts:\n",
    "    if not np.isnan(cinnabar_calc_pert_dict[lig][0]):\n",
    "        x.append(cinnabar_calc_pert_dict[lig][0])\n",
    "        xerr.append(cinnabar_calc_pert_dict[lig][1])\n",
    "        y.append(exper_pert_dict[lig][0])\n",
    "        yerr.append(exper_pert_dict[lig][1])\n",
    "\n",
    "res = stats_engines.compute_stats(x=x, xerr=xerr,\n",
    "                                  y=y, yerr=yerr,\n",
    "                                  statistic=\"RMSE\")\n",
    "print(\"RMSE\", prot, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cinnabar_dicts = {}\n",
    "for prot in ana_obj_dict.keys():\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    files = [f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_fepplus.csv\"]\n",
    "\n",
    "    calc_diff_dict = make_dict.comp_results(\n",
    "        files\n",
    "    )  # older method\n",
    "\n",
    "    perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "\n",
    "    exper_dict = exper_dict_missing[prot]\n",
    "    # exper_dict = ana_obj.exper_val_dict\n",
    "    # for lig in ligs:\n",
    "    #     if lig not in exper_dict.keys():\n",
    "    #         exper_dict[lig] = exper_dict_missing[prot][lig]\n",
    "\n",
    "    convert.cinnabar_file(\n",
    "        [f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_fepplus.csv\"],\n",
    "        exper_dict,\n",
    "        f\"/home/anna/Documents/benchmark/inputs/{prot}/cinnabar\",\n",
    "        perturbations=perts,\n",
    "        method=None,\n",
    "    )\n",
    "\n",
    "    # compute the per ligand for the network\n",
    "    network = wrangle.FEMap(f\"/home/anna/Documents/benchmark/inputs/{prot}/cinnabar.csv\")\n",
    "\n",
    "    # for self plotting of per ligand\n",
    "    cinnabar_calc_val_dict = make_dict.from_cinnabar_network_node(network, \"calc\")\n",
    "    cinnabar_dicts[prot] = cinnabar_calc_val_dict\n",
    "\n",
    "    # normalise exper dict\n",
    "    normalised_exper_dict = {}\n",
    "    avg = np.mean([val[0] for val in exper_dict.values()])\n",
    "    for lig in exper_dict:\n",
    "        normalised_exper_dict[lig] = (exper_dict[lig][0] - avg,exper_dict[lig][1])\n",
    "    x = []\n",
    "    y = []\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    xerr = []\n",
    "    yerr = []\n",
    "    xerrdata = []\n",
    "    yerrdata = []\n",
    "    for lig in ligs:\n",
    "        if not np.isnan(cinnabar_calc_val_dict[lig][0]):\n",
    "            x.append(cinnabar_calc_val_dict[lig][0])\n",
    "            xerr.append(cinnabar_calc_val_dict[lig][1])\n",
    "            xdata.append(fep_lig_dict[prot][lig][0])\n",
    "            xerrdata.append(fep_lig_dict[prot][lig][1])\n",
    "            y.append(normalised_exper_dict[lig][0])\n",
    "            yerr.append(normalised_exper_dict[lig][1])\n",
    "            ydata.append(exper_dict[lig][0])\n",
    "            yerrdata.append(exper_dict[lig][1])\n",
    "\n",
    "    # print(x,y,xerr,yerr)\n",
    "    res = stats_engines.compute_stats(x=x, xerr=xerr,\n",
    "                                        y=y, yerr=yerr,\n",
    "                                        statistic=\"MUE\")\n",
    "    print(\"MAE cinnabar\", prot, res)\n",
    "    res = stats_engines.compute_stats(x=xdata, xerr=xerrdata,\n",
    "                                      y=ydata, yerr=yerrdata,\n",
    "                                      statistic=\"MUE\")\n",
    "    print(\"MAE cc\", prot, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the updated exp values to calc mae\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    files = [f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_fepplus.csv\"]\n",
    "\n",
    "    calc_diff_dict = make_dict.comp_results(\n",
    "        files\n",
    "    )  # older method\n",
    "\n",
    "    perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "\n",
    "    ana_obj.exper_val_dict = exper_dict_missing[prot]\n",
    "    normalised_exper_dict = {}\n",
    "    avg = np.mean([val[0] for val in ana_obj.exper_val_dict.values()])\n",
    "    for lig in ana_obj.exper_val_dict.keys():\n",
    "        normalised_exper_dict[lig] = (ana_obj.exper_val_dict[lig][0] - avg, ana_obj.exper_val_dict[lig][1])\n",
    "    ana_obj.normalised_exper_val_dict = normalised_exper_dict\n",
    "\n",
    "    ana_obj._initialise_stats_object(check=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_dict = {}\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    mae_dict[prot] = {}\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    mae = ana_obj.calc_r2_engines(pert_val=\"val\", recalculate=True)\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        print(\n",
    "            f\"{eng} MAE: {mae[0][eng]['experimental']:.2f} {mae[2][eng]['experimental']}\")\n",
    "        mae_dict[prot][eng] = (\n",
    "            mae[0][eng]['experimental'], mae[1][eng]['experimental'], mae[2][eng]['experimental'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mae_dict).applymap(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in ana_obj_dict.keys():\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    files = [f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_fepplus.csv\"]\n",
    "\n",
    "    calc_diff_dict = make_dict.comp_results(\n",
    "        files\n",
    "    )  # older method\n",
    "\n",
    "    perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "\n",
    "    exper_dict = ana_obj.exper_val_dict\n",
    "    for lig in ligs:\n",
    "        try:\n",
    "            print(lig, exper_dict[lig], exper_dict_missing[prot][lig])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in ana_obj_dict.keys():\n",
    "    \n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "    use_perts = []\n",
    "    reverse_perts = []\n",
    "    for pert in ana_obj.perturbations:\n",
    "        if pert in jacs_dict[prot].keys():\n",
    "            use_perts.append(pert)\n",
    "        if f\"{pert.split('~')[1]}~{pert.split('~')[0]}\" in jacs_dict[prot].keys():\n",
    "            reverse_perts.append(pert)\n",
    "    print(prot, len(use_perts))\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        x = []\n",
    "        y = []\n",
    "        yexp = []\n",
    "        xerr = []\n",
    "        yerr = []\n",
    "        yerrexp = []\n",
    "        for pert in use_perts:\n",
    "            try:\n",
    "                if not np.isnan(ana_obj.calc_pert_dict[eng][pert][0]):\n",
    "                    if not np.isnan(jacs_dict[prot][pert][0]):\n",
    "                        x.append(ana_obj.calc_pert_dict[eng][pert][0])\n",
    "                        xerr.append(ana_obj.calc_pert_dict[eng][pert][1])\n",
    "                        y.append(jacs_dict[prot][pert][0])\n",
    "                        yerr.append(jacs_dict[prot][pert][1])\n",
    "                        yexp.append(ana_obj.exper_pert_dict[pert][0])\n",
    "                        yerrexp.append(ana_obj.exper_pert_dict[pert][1])\n",
    "                    else:\n",
    "                        print(f\"{pert} shroedinger is none\")\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "        for pert in reverse_perts:\n",
    "            try:\n",
    "                if not np.isnan(ana_obj.calc_pert_dict[eng][pert][0]):\n",
    "                    if not np.isnan(jacs_dict[prot][f\"{pert.split('~')[1]}~{pert.split('~')[0]}\"][0]):\n",
    "                        x.append(ana_obj.calc_pert_dict[eng][pert][0])\n",
    "                        xerr.append(ana_obj.calc_pert_dict[eng][pert][1])\n",
    "                        y.append(\n",
    "                            -jacs_dict[prot][f\"{pert.split('~')[1]}~{pert.split('~')[0]}\"][0])\n",
    "                        yerr.append(\n",
    "                            jacs_dict[prot][f\"{pert.split('~')[1]}~{pert.split('~')[0]}\"][1])\n",
    "                        yexp.append(ana_obj.exper_pert_dict[pert][0])\n",
    "                        yerrexp.append(ana_obj.exper_pert_dict[pert][1])\n",
    "                    else:\n",
    "                        print(f\"{pert} shroedinger is none\")\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        # print(x,y,xerr,yerr)\n",
    "        res = stats_engines.compute_stats(x=x, xerr=xerr,\n",
    "                                            y=y, yerr=yerr,\n",
    "                                            statistic=\"MUE\")\n",
    "        print(\"MUE\", prot, eng, res)\n",
    "\n",
    "        res = stats_engines.compute_stats(x=x, xerr=xerr,\n",
    "                                          y=yexp, yerr=yerrexp,\n",
    "                                          statistic=\"RMSE\")\n",
    "        print(\"RMSE me\", prot, eng, res)\n",
    "\n",
    "    res = stats_engines.compute_stats(x=y, xerr=yerr,\n",
    "                                        y=yexp, yerr=yerrexp,\n",
    "                                        statistic=\"RMSE\")\n",
    "    print(\"RMSE shroedinger\", prot, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_ligs = [\"lig_ejm44\", \"lig_ejm49\", \"lig_ejm53\",\n",
    "               \"lig_23\", \"lig_26\", \"lig_29\", \"lig_38\", \"lig_40\", \"lig_42\", \"lig_44\",\n",
    "               \"lig_2cc\",\"lig_2dd\",\"lig_2q\", \"lig_2u\"\n",
    "               ]\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "    use_perts = []\n",
    "    reverse_perts = []\n",
    "    for pert in ana_obj.perturbations:\n",
    "        if pert in jacs_dict[prot].keys():\n",
    "            use_perts.append(pert)\n",
    "        if f\"{pert.split('~')[1]}~{pert.split('~')[0]}\" in jacs_dict[prot].keys():\n",
    "            reverse_perts.append(pert)\n",
    "    print(prot, len(use_perts), use_perts)\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        for pert in use_perts:\n",
    "            try:\n",
    "                if 1 > abs(ana_obj.calc_pert_dict[eng][pert][0]-jacs_dict[prot][pert][0]) > 0.5:   \n",
    "                    # for lig in manual_ligs:\n",
    "                    #     if lig in pert:\n",
    "                        #     print(eng, pert, \"manual ligand\")\n",
    "                        # else:\n",
    "                    print(eng, pert)\n",
    "            except:\n",
    "                pass\n",
    "        for pert in reverse_perts:\n",
    "            try:\n",
    "                if 1 > abs(ana_obj.calc_pert_dict[eng][pert][0]-(-jacs_dict[prot][pert][0])) > 0.5:\n",
    "                    # for lig in manual_ligs:\n",
    "                    #     if lig in pert:\n",
    "                    #         print(eng, pert, \"manual ligand\")\n",
    "                    #     else:\n",
    "                    print(eng, pert)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "# mols = Chem.SDMolSupplier(\n",
    "#     \"/home/anna/Documents/benchmark/inputs/jacs2015_inputs/p38_ligands.sdf\")\n",
    "# for mol in mols:\n",
    "#     # print(mol.GetProp(\"_Name\"))\n",
    "#     with Chem.SDWriter(f'/home/anna/Documents/benchmark/inputs/jacs2015_inputs/p38_ligands/lig_{mol.GetProp(\"_Name\").replace(\"p38a_\",\"\").replace(\"_\",\"\")}.sdf') as w:\n",
    "#         w.write(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the rmsd for the structures\n",
    "\n",
    "ligands = BSS.IO.readMolecules(\n",
    "    \"/home/anna/Documents/benchmark/inputs/jacs2015_inputs/tyk2_ligands/lig_jmc28.sdf\")[0]\n",
    "for lig in ligands:\n",
    "    print(lig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
