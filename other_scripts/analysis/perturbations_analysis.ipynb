{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis paper\n",
    "# import libraries\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as _stats\n",
    "from functools import reduce\n",
    "from pipeline.analysis import *\n",
    "from pipeline.utils import validate\n",
    "from pipeline import *\n",
    "import logging\n",
    "import networkx as nx\n",
    "import glob\n",
    "from scipy.stats import sem as sem\n",
    "from matplotlib import colormaps\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(1, \"/home/anna/Documents/code/python/pipeline\")\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "# warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "print(BSS.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normal_dist(values):\n",
    "    # check normally dist\n",
    "    if len(values) < 50:\n",
    "        stat, p = _stats.shapiro(values)\n",
    "    else:\n",
    "        stat, p = _stats.kstest(values)\n",
    "    if p < 0.05:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def flatten_comprehension(matrix):\n",
    "    return [item for row in matrix for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the analysis method to use\n",
    "ana_dicts = {\n",
    "    \"plain\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": False,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"subsampling\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"1ns\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 25,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"2ns\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 50,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"3ns\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 75,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"autoeq\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": True,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    # \"TI\": {\n",
    "    # \"estimator\": \"TI\",\n",
    "    # \"method\": \"alchemlyb\",\n",
    "    # \"check overlap\": True,\n",
    "    # \"try pickle\": True,\n",
    "    # \"save pickle\": True,\n",
    "    # \"auto equilibration\": False,\n",
    "    # \"statistical inefficiency\": True,\n",
    "    # \"truncate lower\": 0,\n",
    "    # \"truncate upper\": 100,\n",
    "    # \"name\": None,\n",
    "    # },\n",
    "    #     \"single_0\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    #     \"single_1\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    #     \"single_2\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables\n",
    "network = \"combined\"  # lomap rbfenn combined\n",
    "\n",
    "prot_dict_name = {\n",
    "    \"tyk2\": \"TYK2\",\n",
    "    \"mcl1\": \"MCL1\",\n",
    "    \"p38\": \"P38Î±\",\n",
    "    \"syk\": \"SYK\",\n",
    "    \"hif2a\": \"HIF2A\",\n",
    "    \"cmet\": \"CMET\",\n",
    "}\n",
    "eng_dict_name = {\"AMBER\": \"AMBER22\", \"SOMD\": \"SOMD1\", \"GROMACS\": \"GROMACS23\"}\n",
    "\n",
    "# all the options\n",
    "ana_obj_dict = {}\n",
    "\n",
    "for protein in [\"tyk2\", \"mcl1\", \"p38\", \"syk\", \"hif2a\", \"cmet\"]:\n",
    "    ana_obj_dict[protein] = {}\n",
    "\n",
    "    for ana_dict in ana_dicts:\n",
    "        ana_prot = analysis_protocol(ana_dicts[ana_dict])\n",
    "        print(protein, ana_dict)\n",
    "\n",
    "        if protein == \"syk\" or protein == \"cmet\":\n",
    "            main_dir = f\"/backup/{protein}/neutral\"\n",
    "        else:\n",
    "            main_dir = f\"/backup/{protein}\"\n",
    "\n",
    "        bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "\n",
    "        # if need size of protein\n",
    "        try:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.gro\",\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.top\",\n",
    "                ]\n",
    "            )[0]\n",
    "        except:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.prm7\",\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.rst7\",\n",
    "                ]\n",
    "            )[0]\n",
    "\n",
    "        print(f\"no of residues in the protein: {prot.nResidues()}\")\n",
    "\n",
    "        # choose location for the files\n",
    "        if protein == \"syk\" or protein == \"cmet\" or protein == \"hif2a\":\n",
    "            # the lomap network\n",
    "            net_file = f\"{main_dir}/execution_model/network_all.dat\"\n",
    "        else:\n",
    "            net_file = f\"{main_dir}/execution_model/network_{network}.dat\"\n",
    "\n",
    "        exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "        output_folder = f\"{main_dir}/outputs_extracted\"\n",
    "\n",
    "        # prot_file = f\"{main_dir}/execution_model/protocol.dat\" # no protocol used , name added after if needed\n",
    "        pipeline_prot = pipeline_protocol(auto_validate=True)\n",
    "        # pipeline_prot.name(\"\")\n",
    "\n",
    "        # initialise the network object\n",
    "        all_analysis_object = analysis_network(\n",
    "            output_folder,\n",
    "            exp_file=exp_file,\n",
    "            net_file=net_file,\n",
    "            analysis_prot=ana_prot,\n",
    "            method=pipeline_prot.name(),  # if the protocol had a name\n",
    "            engines=pipeline_prot.engines(),\n",
    "        )\n",
    "\n",
    "        # compute\n",
    "        all_analysis_object.compute_results()\n",
    "\n",
    "        if ana_dict == \"single\":\n",
    "            all_analysis_object.file_ext = all_analysis_object.file_ext + f\"_{ana_dict}\"\n",
    "\n",
    "        # add ligands folder\n",
    "        if os.path.isdir(f\"{bench_folder}/inputs/{protein}/ligands\"):\n",
    "            all_analysis_object.add_ligands_folder(\n",
    "                f\"{bench_folder}/inputs/{protein}/ligands\"\n",
    "            )\n",
    "        else:\n",
    "            all_analysis_object.add_ligands_folder(\n",
    "                f\"{bench_folder}/inputs/{protein}/ligands_neutral\"\n",
    "            )\n",
    "\n",
    "        ana_obj_dict[protein][ana_dict] = all_analysis_object\n",
    "\n",
    "print(ana_obj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make single vs triplicate results\n",
    "for prot in ana_obj_dict.keys():\n",
    "    for r in range(0, 3, 1):\n",
    "        ana_obj = ana_obj_dict[prot][f\"single_{r}\"]\n",
    "        # function for single dicts\n",
    "        ana_obj.compute_single_repeat_results(repeat=r)\n",
    "        # for eng in [\"AMBER\",\"SOMD\",\"GROMACS\"]:\n",
    "        #     print(prot, eng)\n",
    "        #     ana_obj.change_name(eng, f\"{eng}_old\")\n",
    "        #     ana_obj.change_name(f\"{eng}_single\", eng)\n",
    "        #     if eng not in ana_obj.engines:\n",
    "        #         ana_obj.engines.append(eng)\n",
    "        #     if eng in ana_obj.other_results_names:\n",
    "        #         ana_obj.other_results_names.remove(eng)\n",
    "        # print(ana_obj.engines + ana_obj.other_results_names)\n",
    "        # print(ana_obj.calc_pert_dict[eng])\n",
    "\n",
    "# # error for a perturbation per single run\n",
    "\n",
    "# uncertainty_dict_single = {}\n",
    "\n",
    "# for eng in all_analysis_object.engines:\n",
    "#     uncertainty_dict_single[eng] = {}\n",
    "#     repeat = 0\n",
    "#     for file in all_analysis_object._results_repeat_files[eng]:\n",
    "#         uncertainty_dict_single[eng][repeat] = {}\n",
    "#         calc_diff_dict = make_dict.comp_results(\n",
    "#             file, all_analysis_object.perturbations, eng, name=None\n",
    "#         )\n",
    "\n",
    "#         for pert in calc_diff_dict.keys():\n",
    "#             uncertainty_dict_single[eng][repeat][pert] = calc_diff_dict[pert][1]\n",
    "\n",
    "#         repeat += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot convergence. only plot if has been computed (should have run for not stats ineff)\n",
    "\n",
    "# for prot in ana_obj_dict.keys():\n",
    "\n",
    "#     try:\n",
    "#         ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "#         ana_obj.compute_convergence(\n",
    "#             compute_missing=True\n",
    "#         )\n",
    "#         ana_obj.plot_convergence()\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(f\"could not for {prot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify any outliers and plot again if needed above\n",
    "failed_perts_dict_percen = {}\n",
    "failed_perts_dict = {}\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    failed_perts_dict_percen[prot] = {}\n",
    "    failed_perts_dict[prot] = {}\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "    print(prot)\n",
    "    for eng in ana_obj.engines:  # ana_obj.engines\n",
    "        failed_perts_dict_percen[prot][eng] = (\n",
    "            100 - ana_obj.successful_perturbations(eng)[1]\n",
    "        )\n",
    "        failed_perts_dict[prot][eng] = len(ana_obj.failed_perturbations(eng))\n",
    "        print(\n",
    "            f\"failed percentage for {eng}: {100 - ana_obj.successful_perturbations(eng)[1]} ({len(ana_obj.perturbations) - len(ana_obj.successful_perturbations(eng)[2])} / {len(ana_obj.perturbations)})\"\n",
    "        )\n",
    "        print(f\"{eng} failed perturbations: {ana_obj.failed_perturbations(engine=eng)}\")\n",
    "        print(f\"{eng} disconnected ligands: {ana_obj.disconnected_ligands(engine=eng)}\")\n",
    "        print(f\"outliers {eng}: {ana_obj.get_outliers(threshold=10, name=eng)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj = ana_obj_dict[\"p38\"][\"subsampling\"]\n",
    "ana_obj.draw_perturbations(ana_obj.get_outliers(threshold=10, name=\"SOMD\"))\n",
    "[\n",
    "    (pert, ana_obj.calc_pert_dict[\"SOMD\"][pert])\n",
    "    for pert in ana_obj.get_outliers(threshold=10, name=\"SOMD\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the 2 fs and reverse runs\n",
    "failed_dict = {\n",
    "    \"tyk2\": {\n",
    "        \"AMBER\": [\"lig_jmc27~lig_jmc28\"],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"mcl1\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_38~lig_44\",\n",
    "            \"lig_27~lig_40\",\n",
    "            \"lig_38~lig_40\",\n",
    "            \"lig_33~lig_40\",\n",
    "            \"lig_30~lig_40\",\n",
    "            \"lig_27~lig_38\",\n",
    "        ],\n",
    "        \"SOMD\": [\"lig_38~lig_48\"],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"p38\": {\n",
    "        \"AMBER\": [\"lig_2b~lig_2z\", \"lig_2aa~lig_2z\", \"lig_2o~lig_2s\", \"lig_2n~lig_2s\"],\n",
    "        \"SOMD\": [\n",
    "            \"lig_2u~lig_2x\",\n",
    "            \"lig_2b~lig_2l\",\n",
    "            \"lig_2a~lig_2q\",\n",
    "            \"lig_2ff~lig_2hh\",\n",
    "            \"lig_2h~lig_2m\",\n",
    "        ],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"syk\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_1~lig_13\",\n",
    "            \"lig_33~lig_38\",\n",
    "            \"lig_21~lig_37\",\n",
    "            \"lig_21~lig_8\",\n",
    "            \"lig_28~lig_42\",\n",
    "        ],\n",
    "        \"SOMD\": [\"lig_1~lig_13\"],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"hif2a\": {\n",
    "        \"AMBER\": [\"lig_41~lig_9\", \"lig_35~lig_36\"],\n",
    "        \"SOMD\": [\"lig_27~lig_8\"],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"cmet\": {\n",
    "        \"AMBER\": [\"lig_1~lig_4\", \"lig_1~lig_6\", \"lig_10~lig_17\"],\n",
    "        \"SOMD\": [\"lig_1~lig_6\"],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "}\n",
    "twofs_run_dict = {\n",
    "    \"tyk2\": {\n",
    "        \"AMBER\": [],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"mcl1\": {\n",
    "        \"AMBER\": [\"lig_27~lig_59\", \"lig_33~lig_48\", \"lig_30~lig_31\", \"lig_35~lig_36\"],\n",
    "        \"SOMD\": [\"lig_27~lig_40\", \"lig_27~lig_45\", \"lig_27~lig_47\"],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"p38\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_2b~lig_2l\",\n",
    "            \"lig_2e~lig_2q\",\n",
    "            \"lig_2v~lig_2y\",\n",
    "            \"lig_2e~lig_2r\",\n",
    "            \"lig_2a~lig_2r\",\n",
    "            \"lig_2dd~lig_2hh\",\n",
    "            \"lig_2k~lig_2q\",\n",
    "            \"lig_2n~lig_2p\",\n",
    "            \"lig_2ee~lig_2ff\",\n",
    "            \"lig_2h~lig_2n\",\n",
    "            \"lig_2k~lig_2l\",\n",
    "        ],\n",
    "        \"SOMD\": [\"lig_2m~lig_2x\", \"lig_2t~lig_2x\", \"lig_2l~lig_2x\", \"lig_2ff~lig_2m\"],\n",
    "        \"GROMACS\": [\"lig_2t~lig_2x\", \"lig_2l~lig_2t\"],\n",
    "    },\n",
    "    \"syk\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_21~lig_41\",\n",
    "            \"lig_37~lig_41\",\n",
    "            \"lig_1~lig_41\",\n",
    "            \"lig_11~lig_5\",\n",
    "            \"lig_29~lig_40\",\n",
    "            \"lig_11~lig_34\",\n",
    "            \"lig_19~lig_40\",\n",
    "            \"lig_10~lig_42\",\n",
    "            \"lig_16~lig_17\",\n",
    "            \"lig_19~lig_25\",\n",
    "            \"lig_23~lig_42\",\n",
    "            \"lig_33~lig_40\",\n",
    "            \"lig_2~lig_20\",\n",
    "            \"lig_2~lig_30\",\n",
    "            \"lig_28~lig_35\",\n",
    "            \"lig_38~lig_44\",\n",
    "            \"lig_6~lig_7\",\n",
    "            \"lig_35~lig_42\",\n",
    "            \"lig_39~lig_42\",\n",
    "            \"lig_39~lig_7\",\n",
    "            \"lig_20~lig_30\",\n",
    "            \"lig_27~lig_38\",\n",
    "        ],\n",
    "        \"SOMD\": [\"lig_21~lig_41\", \"lig_37~lig_41\", \"lig_38~lig_44\"],\n",
    "        \"GROMACS\": [\"lig_28~lig_42\"],\n",
    "    },\n",
    "    \"hif2a\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_3~lig_31\",\n",
    "            \"lig_31~lig_41\",\n",
    "            \"lig_20~lig_37\",\n",
    "            \"lig_15~lig_32\",\n",
    "            \"lig_20~lig_40\",\n",
    "            \"lig_24~lig_5\",\n",
    "            \"lig_32~lig_6\",\n",
    "            \"lig_34~lig_35\",\n",
    "            \"lig_41~lig_6\",\n",
    "            \"lig_19~lig_6\",\n",
    "            \"lig_24~lig_37\",\n",
    "            \"lig_29~lig_7\",\n",
    "            \"lig_14~lig_42\",\n",
    "            \"lig_25~lig_26\",\n",
    "            \"lig_27~lig_3\",\n",
    "            \"lig_28~lig_8\",\n",
    "            \"lig_21~lig_25\",\n",
    "            \"lig_21~lig_39\",\n",
    "            \"lig_33~lig_42\",\n",
    "            \"lig_34~lig_6\",\n",
    "            \"lig_1~lig_25\",\n",
    "            \"lig_14~lig_38\",\n",
    "            \"lig_15~lig_6\",\n",
    "            \"lig_16~lig_4\",\n",
    "            \"lig_21~lig_33\",\n",
    "            \"lig_21~lig_42\",\n",
    "            \"lig_22~lig_8\",\n",
    "            \"lig_25~lig_33\",\n",
    "            \"lig_30~lig_6\",\n",
    "            \"lig_10~lig_21\",\n",
    "            \"lig_17~lig_42\",\n",
    "        ],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"cmet\": {\n",
    "        \"AMBER\": [\"lig_17 lig_6\", \"lig_4 lig_5\", \"lig_22 lig_3\"],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [\"lig_7~lig_9\"],\n",
    "    },\n",
    "}\n",
    "reverse_run_dict = {\n",
    "    \"tyk2\": {\n",
    "        \"AMBER\": [],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"mcl1\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_27~lig_43\",\n",
    "        ],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"p38\": {\n",
    "        \"AMBER\": [\"lig_2a~lig_2h\"],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"syk\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_40~lig_42\",\n",
    "            \"lig_40~lig_6\",\n",
    "            \"lig_25~lig_29\",\n",
    "            \"lig_26~lig_6\",\n",
    "            \"lig_36~lig_6\",\n",
    "            \"lig_27~lig_44\",\n",
    "            \"lig_26~lig_36\",\n",
    "        ],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"hif2a\": {\n",
    "        \"AMBER\": [],\n",
    "        \"SOMD\": [],\n",
    "        \"GROMACS\": [],\n",
    "    },\n",
    "    \"cmet\": {\n",
    "        \"AMBER\": [\n",
    "            \"lig_7~lig_9\",\n",
    "            \"lig_22~lig_9\",\n",
    "            \"lig_1~lig_10\",\n",
    "            \"lig_1~lig_17\",\n",
    "            \"lig_18~lig_7\",\n",
    "        ],\n",
    "        \"SOMD\": [\"lig_22~lig_9\"],\n",
    "        \"GROMACS\": [\"lig_22~lig_9\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "failed_actual_dict = {\n",
    "    \"tyk2\": {\n",
    "        \"AMBER\": len(failed_dict[\"tyk2\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(failed_dict[\"tyk2\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(failed_dict[\"tyk2\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"mcl1\": {\n",
    "        \"AMBER\": len(failed_dict[\"mcl1\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(failed_dict[\"mcl1\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(failed_dict[\"mcl1\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"p38\": {\n",
    "        \"AMBER\": len(failed_dict[\"p38\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(failed_dict[\"p38\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(failed_dict[\"p38\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"syk\": {\n",
    "        \"AMBER\": len(failed_dict[\"syk\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(failed_dict[\"syk\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(failed_dict[\"syk\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"hif2a\": {\n",
    "        \"AMBER\": len(failed_dict[\"hif2a\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(failed_dict[\"hif2a\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(failed_dict[\"hif2a\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"cmet\": {\n",
    "        \"AMBER\": len(failed_dict[\"cmet\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(failed_dict[\"cmet\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(failed_dict[\"cmet\"][\"GROMACS\"]),\n",
    "    },\n",
    "}\n",
    "twofs_dict = {\n",
    "    \"tyk2\": {\n",
    "        \"AMBER\": len(twofs_run_dict[\"tyk2\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(twofs_run_dict[\"tyk2\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(twofs_run_dict[\"tyk2\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"mcl1\": {\n",
    "        \"AMBER\": len(twofs_run_dict[\"mcl1\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(twofs_run_dict[\"mcl1\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(twofs_run_dict[\"mcl1\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"p38\": {\n",
    "        \"AMBER\": len(twofs_run_dict[\"p38\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(twofs_run_dict[\"p38\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(twofs_run_dict[\"p38\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"syk\": {\n",
    "        \"AMBER\": len(twofs_run_dict[\"syk\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(twofs_run_dict[\"syk\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(twofs_run_dict[\"syk\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"hif2a\": {\n",
    "        \"AMBER\": len(twofs_run_dict[\"hif2a\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(twofs_run_dict[\"hif2a\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(twofs_run_dict[\"hif2a\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"cmet\": {\n",
    "        \"AMBER\": len(twofs_run_dict[\"cmet\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(twofs_run_dict[\"cmet\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(twofs_run_dict[\"cmet\"][\"GROMACS\"]),\n",
    "    },\n",
    "}\n",
    "reverse_dict = {\n",
    "    \"tyk2\": {\n",
    "        \"AMBER\": len(reverse_run_dict[\"tyk2\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(reverse_run_dict[\"tyk2\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(reverse_run_dict[\"tyk2\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"mcl1\": {\n",
    "        \"AMBER\": len(reverse_run_dict[\"mcl1\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(reverse_run_dict[\"mcl1\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(reverse_run_dict[\"mcl1\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"p38\": {\n",
    "        \"AMBER\": len(reverse_run_dict[\"p38\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(reverse_run_dict[\"p38\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(reverse_run_dict[\"p38\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"syk\": {\n",
    "        \"AMBER\": len(reverse_run_dict[\"syk\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(reverse_run_dict[\"syk\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(reverse_run_dict[\"syk\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"hif2a\": {\n",
    "        \"AMBER\": len(reverse_run_dict[\"hif2a\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(reverse_run_dict[\"hif2a\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(reverse_run_dict[\"hif2a\"][\"GROMACS\"]),\n",
    "    },\n",
    "    \"cmet\": {\n",
    "        \"AMBER\": len(reverse_run_dict[\"cmet\"][\"AMBER\"]),\n",
    "        \"SOMD\": len(reverse_run_dict[\"cmet\"][\"SOMD\"]),\n",
    "        \"GROMACS\": len(reverse_run_dict[\"cmet\"][\"GROMACS\"]),\n",
    "    },\n",
    "}\n",
    "\n",
    "df_failed = pd.DataFrame(failed_actual_dict).T\n",
    "df_twofs = pd.DataFrame(twofs_dict).T\n",
    "df_reverse = pd.DataFrame(reverse_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the failed perturbations\n",
    "# df = pd.DataFrame(failed_perts_dict_percen).T\n",
    "# ax =df.plot(color=pipeline.analysis.set_colours(),\n",
    "#     kind=\"bar\", xlabel=\"Protein System\", ylabel=\"failed perturbations (%)\")\n",
    "\n",
    "\n",
    "ax = df_failed.plot(\n",
    "    color=pipeline.analysis.set_colours(),\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=\"number of failed perturbations\",\n",
    ")\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_protocol_dict = {\n",
    "    \"AMBER\": {\n",
    "        \"4 fs\": 376\n",
    "        - (\n",
    "            np.sum(df_reverse[\"AMBER\"])\n",
    "            + np.sum(df_twofs[\"AMBER\"])\n",
    "            + np.sum(df_failed[\"AMBER\"])\n",
    "        ),\n",
    "        \"2 fs\": np.sum(df_reverse[\"AMBER\"]),\n",
    "        \"2 fs reverse\": np.sum(df_twofs[\"AMBER\"]),\n",
    "        \"failed\": np.sum(df_failed[\"AMBER\"]),\n",
    "    },\n",
    "    \"GROMACS\": {\n",
    "        \"4 fs\": 376\n",
    "        - (\n",
    "            np.sum(df_reverse[\"GROMACS\"])\n",
    "            + np.sum(df_twofs[\"GROMACS\"])\n",
    "            + np.sum(df_failed[\"GROMACS\"])\n",
    "        ),\n",
    "        \"2 fs\": np.sum(df_reverse[\"GROMACS\"]),\n",
    "        \"2 fs reverse\": np.sum(df_twofs[\"GROMACS\"]),\n",
    "        \"failed\": np.sum(df_failed[\"GROMACS\"]),\n",
    "    },\n",
    "    \"SOMD\": {\n",
    "        \"4 fs\": 376\n",
    "        - (\n",
    "            np.sum(df_reverse[\"SOMD\"])\n",
    "            + np.sum(df_twofs[\"SOMD\"])\n",
    "            + np.sum(df_failed[\"SOMD\"])\n",
    "        ),\n",
    "        \"2 fs\": np.sum(df_reverse[\"SOMD\"]),\n",
    "        \"2 fs reverse\": np.sum(df_twofs[\"SOMD\"]),\n",
    "        \"failed\": np.sum(df_failed[\"SOMD\"]),\n",
    "    },\n",
    "}\n",
    "# for key in adaptive_protocol_dict:\n",
    "#     print(key)\n",
    "#     assert np.sum(adaptive_protocol_dict[key].values) == 376\n",
    "# total no of perturbations is 376\n",
    "df = pd.DataFrame(adaptive_protocol_dict).T.rename(eng_dict_name)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.25, 3.25))\n",
    "df.plot(\n",
    "    color=[\"darkslateblue\", \"purple\", \"orchid\", \"lavender\"],\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"MD engine\",\n",
    "    ylabel=\"Number of perturbations\",\n",
    "    ax=ax,\n",
    "    width=0.8,\n",
    ")\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        str(p.get_height()), (p.get_x() - 0.05, p.get_height() * 1.005), fontsize=7\n",
    "    )\n",
    "ax.legend(loc=\"center right\", fontsize=10)\n",
    "plt.xlabel(\"MD Engine\", fontsize=12)\n",
    "plt.ylabel(\"Number of perturbations\", fontsize=12)\n",
    "plt.tick_params(axis=\"x\", labelsize=10, rotation=45)\n",
    "plt.tick_params(axis=\"y\", labelsize=10, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max sem\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude outliers\n",
    "threshold = 10\n",
    "for prot in ana_obj_dict.keys():\n",
    "    for name in ana_dicts.keys():\n",
    "        print(prot, name)\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            ana_obj.file_ext = ana_obj.file_ext + f\"_outliers{threshold}removed\"\n",
    "            ana_obj.remove_outliers(threshold=threshold, name=eng)\n",
    "        # print(ana_obj.file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_range(val_list):\n",
    "    min_val = min(val_list)\n",
    "    max_val = max(val_list)\n",
    "    # print(min_val)\n",
    "    # print(max_val)\n",
    "\n",
    "    return max_val[0] - min_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max edge range\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # names = [val for val in ana_obj.calc_pert_dict[eng].keys()]\n",
    "        # vals = [val[0] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "        # sems = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "        # print(prot, eng, names[sems.index(max(sems))],\n",
    "        #       vals[sems.index(max(sems))], sems[sems.index(max(sems))])\n",
    "        ranges = []\n",
    "        for pert in ana_obj._perturbations_dict[eng]:\n",
    "            try:\n",
    "                ra = val_range(\n",
    "                    [ana_obj.calc_repeat_pert_dict[eng][r][pert] for r in [0, 1, 2]]\n",
    "                )\n",
    "                ranges.append(ra)\n",
    "            except:\n",
    "                pass\n",
    "        clean_ranges = [x for x in ranges if str(x) != \"nan\"]\n",
    "        print(f\"{eng}, {np.mean(clean_ranges):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj = ana_obj_dict[\"mcl1\"][\"subsampling\"]\n",
    "[ana_obj.calc_repeat_pert_dict[\"SOMD\"][r][\"lig_27~lig_45\"] for r in [0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte the differences in SEM\n",
    "# SEM differences\n",
    "sem_dict = {}\n",
    "sem_dict_name = {}\n",
    "\n",
    "for name in ana_dicts:\n",
    "    sem_list_name = []\n",
    "    sem_dict[name] = {}\n",
    "\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        sem_dict[name][prot] = {}\n",
    "\n",
    "        ana_obj = ana_obj_dict[prot][name]  # subsampling\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            sem_dict[name][prot][eng] = {}\n",
    "\n",
    "            sem_list = []\n",
    "            sems = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "            sem_list.append(sems)\n",
    "            sem_list_name.append(sems)\n",
    "\n",
    "            sem_list = reduce(lambda xs, ys: xs + ys, sem_list)\n",
    "            sem_list = [x for x in sem_list if str(x) != \"nan\"]\n",
    "\n",
    "            # if not check_normal_dist(sem_list):\n",
    "            #     print(f\"{prot} {name} not normally dist\")\n",
    "\n",
    "            mean = np.mean(sem_list)\n",
    "            lower_ci, upper_ci = _stats.norm.interval(\n",
    "                confidence=0.95, loc=np.mean(sem_list), scale=_stats.sem(sem_list)\n",
    "            )\n",
    "            print(prot, name, eng, mean, lower_ci, upper_ci)\n",
    "            sem_dict[name][prot][eng] = (\n",
    "                mean,\n",
    "                _stats.tstd(sem_list),\n",
    "                (lower_ci, upper_ci),\n",
    "                sem_list,\n",
    "            )\n",
    "\n",
    "    sem_list_name = reduce(lambda xs, ys: xs + ys, sem_list_name)\n",
    "    sem_list_name = [x for x in sem_list_name if str(x) != \"nan\"]\n",
    "    mean = np.mean(sem_list_name)\n",
    "    lower_ci, upper_ci = _stats.norm.interval(\n",
    "        confidence=0.95, loc=np.mean(sem_list_name), scale=_stats.sem(sem_list_name)\n",
    "    )\n",
    "    print(name, mean, lower_ci, upper_ci)\n",
    "    sem_dict_name[name] = (\n",
    "        mean,\n",
    "        _stats.tstd(sem_list_name),\n",
    "        (lower_ci, upper_ci),\n",
    "        sem_list_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte the differences in SEM\n",
    "# SEM differences\n",
    "sem_dict = {}\n",
    "sem_dict_name = {}\n",
    "\n",
    "for name in ana_dicts:\n",
    "    for eng in [\"GROMACS\"]:\n",
    "        sem_list = []\n",
    "        for prot in ana_obj_dict.keys():\n",
    "            ana_obj = ana_obj_dict[prot][name]\n",
    "            sems = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "            # print(prot, sems)\n",
    "            sem_list.append(sems)\n",
    "\n",
    "        sem_list = reduce(lambda xs, ys: xs + ys, sem_list)\n",
    "        sem_list = [x for x in sem_list if str(x) != \"nan\"]\n",
    "        print(len(sem_list))\n",
    "        mean = np.mean(sem_list)\n",
    "        lower_ci, upper_ci = _stats.norm.interval(\n",
    "            confidence=0.95, loc=np.mean(sem_list), scale=_stats.sem(sem_list)\n",
    "        )\n",
    "        print(name, eng, mean, lower_ci, upper_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the ddG\n",
    "# also calc mae perts\n",
    "\n",
    "mae_dict = {}\n",
    "\n",
    "for name in ana_dicts:\n",
    "    mae_dict[name] = {}\n",
    "\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        print(prot, name)\n",
    "\n",
    "        mae_dict[name][prot] = {}\n",
    "\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        stats_string_all = \"\"\n",
    "        try:\n",
    "            mae = ana_obj.calc_mae_engines(pert_val=\"pert\", recalculate=False)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            stats_string = \"\"\n",
    "            try:\n",
    "                mae_dict[name][prot][eng] = (\n",
    "                    mae[0][eng][\"experimental\"],\n",
    "                    mae[1][eng][\"experimental\"],\n",
    "                    mae[2][eng][\"experimental\"],\n",
    "                )\n",
    "                stats_string += f\"{eng} MAE: {mae[0][eng]['experimental']:.2f} +/- {mae[1][eng]['experimental']:.2f} kcal/mol, \"\n",
    "\n",
    "                if sem_dict[name][prot][eng][0]:\n",
    "                    stats_string += f\"SEM: {sem_dict[name][prot][eng][0]:.2f} +/- {sem_dict[name][prot][eng][1]:.2f} kcal/mol\\n\"\n",
    "                elif name == \"single\":\n",
    "                    errors = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "                    stats_string += f\"error: {np.mean(errors):.2f} +/- {_stats.tstd(errors):.2f} kcal/mol\\n\"\n",
    "\n",
    "                print(stats_string)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"could not compute for {prot} {name} {eng}\")\n",
    "\n",
    "            # try:\n",
    "            #     ana_obj.plot_scatter_ddG(\n",
    "            #         engines=eng, suptitle=f\"{prot}, {method}\\n\", title=f\"{stats_string}\")\n",
    "            #     ana_obj.plot_scatter_ddG(engines=eng, use_cinnabar=True)\n",
    "            # except:\n",
    "            #     pass\n",
    "            # stats_string_all+=stats_string\n",
    "\n",
    "        # try:\n",
    "        #     ana_obj.plot_scatter_ddG(\n",
    "        #         suptitle=f\"{prot}, {method}\\n \\n \\n \\n \\n\", title=f\"{stats_string_all}\", engines=ana_obj.engines)\n",
    "        # except:\n",
    "        #     print(f\"could not plot {prot} {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs based on engine\n",
    "plotting_dict = mae_dict  # mae_dict or sem_dict\n",
    "stats_name = \"ÎÎG MAE\"  # MAE or SEM\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(20, 20), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "for engine, pos in zip(ana_obj.engines, [axes[0], axes[1], axes[2]]):\n",
    "    df_list = []\n",
    "    df_err_list = []\n",
    "    for name in ana_dicts:\n",
    "        df = (\n",
    "            pd.DataFrame(plotting_dict[name])\n",
    "            .applymap(lambda x: x[0])\n",
    "            .rename(prot_dict_name, axis=1)\n",
    "            .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "            .rename({engine: name}, axis=1)\n",
    "            .rename(\n",
    "                {\n",
    "                    \"plain\": \"Full data\",\n",
    "                    \"subsampling\": \"Subsampling\",\n",
    "                    \"autoeq\": \"Auto-equilibration\",\n",
    "                    \"1ns\": \"1 ns sampling\",\n",
    "                    \"2ns\": \"2 ns sampling\",\n",
    "                    \"3ns\": \"3 ns sampling\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_err = (\n",
    "            pd.DataFrame(plotting_dict[name])\n",
    "            .applymap(lambda x: x[2])\n",
    "            .rename(prot_dict_name, axis=1)\n",
    "            .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "            .rename({engine: name}, axis=1)\n",
    "            .rename(\n",
    "                {\n",
    "                    \"plain\": \"Full data\",\n",
    "                    \"subsampling\": \"Subsampling\",\n",
    "                    \"autoeq\": \"Auto-equilibration\",\n",
    "                    \"1ns\": \"1 ns sampling\",\n",
    "                    \"2ns\": \"2 ns sampling\",\n",
    "                    \"3ns\": \"3 ns sampling\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_lower = df_err.applymap(lambda x: x[0])\n",
    "        df_upper = df_err.applymap(lambda x: x[1])\n",
    "        df_err = (df_upper - df_lower) / 2\n",
    "\n",
    "        df_list.append(df)\n",
    "        df_err_list.append(df_err)\n",
    "\n",
    "    df = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        df_list,\n",
    "    )\n",
    "    df_err = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        df_err_list,\n",
    "    )\n",
    "\n",
    "    print(df)\n",
    "    print(engine)\n",
    "    print(df.mean())\n",
    "    print(df.sem())\n",
    "    print(df_err)\n",
    "\n",
    "    # engine colours\n",
    "    col_dict = {\n",
    "        \"AMBER\": plt.get_cmap(\"autumn\"),\n",
    "        \"SOMD\": plt.get_cmap(\"cool\"),\n",
    "        \"GROMACS\": plt.get_cmap(\"viridis\"),\n",
    "    }\n",
    "\n",
    "    # scale data for compatibility with cmap\n",
    "    data = [i for i in range(1, len(df.columns) + 1)]\n",
    "    den = max(data) - min(data)\n",
    "    scaled_data = [(datum - min(data)) / den for datum in data]\n",
    "\n",
    "    # get colors corresponding to data\n",
    "    colors = []\n",
    "    my_cmap = plt.get_cmap(\"plasma\")  # col_dict[engine]\n",
    "\n",
    "    for decimal in scaled_data:\n",
    "        colors.append(my_cmap(decimal))\n",
    "\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=colors,\n",
    "        yerr=df_err,\n",
    "        title=eng_dict_name[engine],\n",
    "        ax=pos,\n",
    "        xlabel=\"Protein System\",\n",
    "        ylabel=f\"{stats_name} (kcal/mol)\",\n",
    "    )\n",
    "# fig.suptitle(f'{stats_name} perturbations for LOMAP/RBFENN-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for each engine and each method\n",
    "plotting_dict = mae_dict  # mae_dict or sem_dict\n",
    "stats_name = \"ddG MAE\"  # MAE or SEM\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 20), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "\n",
    "df_list = []\n",
    "df_err_list = []\n",
    "for name in ana_dicts:\n",
    "    df = pd.DataFrame(plotting_dict[name]).applymap(lambda x: x[0]).T\n",
    "\n",
    "    df_err = pd.DataFrame(plotting_dict[name]).applymap(lambda x: x[2]).T\n",
    "\n",
    "    df_lower = df_err.applymap(lambda x: x[0])\n",
    "    df_upper = df_err.applymap(lambda x: x[1])\n",
    "    df_err = (df_upper - df_lower) / 2\n",
    "\n",
    "    df_list.append(df)\n",
    "    df_err_list.append(df_err)\n",
    "\n",
    "df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "    df_list,\n",
    ")\n",
    "df_err = reduce(\n",
    "    lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "    df_err_list,\n",
    ")\n",
    "\n",
    "# scale data for compatibility with cmap\n",
    "data = [i for i in range(1, len(df.columns) + 1)]\n",
    "den = max(data) - min(data)\n",
    "scaled_data = [(datum - min(data)) / den for datum in data]\n",
    "\n",
    "# get colors corresponding to data\n",
    "colors = []\n",
    "my_cmap = plt.get_cmap(\"plasma\")\n",
    "\n",
    "for decimal in scaled_data:\n",
    "    colors.append(my_cmap(decimal))\n",
    "\n",
    "df.plot(\n",
    "    kind=\"bar\",\n",
    "    color=colors,\n",
    "    yerr=df_err,\n",
    "    title=engine,\n",
    "    ax=pos,\n",
    "    xlabel=\"MD Engine\",\n",
    "    ylabel=f\"{stats_name} (kcal/mol)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one graph for one method but that compared for each protein\n",
    "plotting_dict = mae_dict  # mae_dict or sem_dict\n",
    "stats_name = \"ddG MAE\"  # MAE or SEM\n",
    "plt.xlim = ()\n",
    "plt.ylim = (0, 2)\n",
    "\n",
    "name = \"subsampling\"\n",
    "df = pd.DataFrame(plotting_dict[name]).applymap(lambda x: x[0]).T\n",
    "df_err = pd.DataFrame(plotting_dict[name]).applymap(lambda x: x[2]).T\n",
    "df_lower = df_err.applymap(lambda x: x[0])\n",
    "df_upper = df_err.applymap(lambda x: x[1])\n",
    "df_err = (df_upper - df_lower) / 2\n",
    "ax = df.plot(\n",
    "    kind=\"bar\",\n",
    "    color=pipeline.analysis.set_colours(),\n",
    "    xlabel=\"protein system\",\n",
    "    ylabel=f\"{stats_name} (kcal/mol)\",\n",
    "    yerr=df_err,\n",
    ")\n",
    "ax.set_ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check significant difference\n",
    "\n",
    "# calculating if the stats for a given dict are actually also sig diff\n",
    "results_dict = mae_dict[\"subsampling\"]\n",
    "\n",
    "for protein in [\"tyk2\", \"mcl1\", \"p38\"]:\n",
    "    for eng1, eng2 in it.product(ana_obj.engines, ana_obj.engines):\n",
    "        results = _stats.ttest_ind_from_stats(\n",
    "            mean1=results_dict[protein][eng1][0],\n",
    "            mean2=results_dict[protein][eng2][0],\n",
    "            std1=results_dict[protein][eng1][1],\n",
    "            std2=results_dict[protein][eng2][1],\n",
    "            nobs1=40,\n",
    "            nobs2=40,\n",
    "        )\n",
    "        print(protein, eng1, eng2, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cinnabar stats into a dict\n",
    "net_ana_method_dict = {\"method\": [], \"engine\": [], \"protein\": [], \"value\": []}\n",
    "\n",
    "for method in list(ana_dicts.keys()) + [\"single_0\", \"single_1\", \"single_2\"]:\n",
    "    for eng in ana_obj.engines:\n",
    "        overall_dg_list = []\n",
    "\n",
    "        for prot in ana_obj_dict.keys():\n",
    "            dg_list = []\n",
    "\n",
    "            if \"single\" in method:\n",
    "                print(f\"method is {method}!\")\n",
    "                ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "                use_dict = ana_obj.calc_repeat_pert_dict[eng][\n",
    "                    int(method.split(\"_\")[-1])\n",
    "                ]\n",
    "            else:\n",
    "                ana_obj = ana_obj_dict[prot][method]\n",
    "                use_dict = ana_obj.calc_pert_dict[eng]\n",
    "\n",
    "            for key in use_dict.keys():\n",
    "                if key not in ana_obj._perturbations_dict[eng]:\n",
    "                    print(f\"{key} not in pert dict\")\n",
    "                    continue\n",
    "                # try:\n",
    "                value = abs(abs(use_dict[key][0] - ana_obj.exper_pert_dict[key][0]))\n",
    "                # if value > 10:\n",
    "                #     print(prot, eng, key, value)\n",
    "                # else:\n",
    "                dg_list.append(value)\n",
    "                # except:\n",
    "                #     print(f\"{key} not in dict for {eng} {method}\")\n",
    "\n",
    "            net_ana_method_dict[\"method\"].append(\n",
    "                [method for l in range(0, len(dg_list))]\n",
    "            )\n",
    "            net_ana_method_dict[\"engine\"].append([eng for l in range(0, len(dg_list))])\n",
    "            net_ana_method_dict[\"protein\"].append([prot for val in dg_list])\n",
    "            net_ana_method_dict[\"value\"].append([val for val in dg_list])\n",
    "            overall_dg_list.append(dg_list)\n",
    "\n",
    "        print(\n",
    "            f\"{eng} {method} mean is {np.mean([dg for dg in flatten_comprehension(overall_dg_list) if dg])}\"\n",
    "        )\n",
    "\n",
    "\n",
    "plotting_dict = {\n",
    "    \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "    \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "    \"MAE ddG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "    \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(plotting_dict)\n",
    "ax = sns.boxplot(df, x=\"MD engine\", y=\"MAE ddG (kcal/mol)\", hue=\"method\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(df, x=\"MAE ddG (kcal/mol)\", hue=\"MD engine\")\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(\n",
    "    df, x=\"MD engine\", y=\"MAE ddG (kcal/mol)\", hue=\"method\", errorbar=(\"ci\")  # 95%\n",
    ")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "val_dict = {\n",
    "    method: {}\n",
    "    for method in list(ana_dicts.keys()) + [\"single_0\", \"single_1\", \"single_2\"]\n",
    "}\n",
    "\n",
    "for p, l, name in zip(\n",
    "    ax.patches,\n",
    "    ax.lines,\n",
    "    it.product(\n",
    "        list(ana_dicts.keys()) + [\"single_0\", \"single_1\", \"single_2\"], ana_obj.engines\n",
    "    ),\n",
    "):\n",
    "    xy = l.get_xydata()\n",
    "    # print(f\"{name}: {p.get_height():.2f} ({xy[0][1]:.2f}, {xy[1][1]:.2f})\")\n",
    "    val_dict[name[0]][\n",
    "        name[1]\n",
    "    ] = f\"{p.get_height():.2f} ({xy[0][1]:.2f}, {xy[1][1]:.2f})\"\n",
    "\n",
    "df_val = pd.DataFrame(val_dict)\n",
    "df_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default autoeq time for each engine\n",
    "# recalculate eq times if needed\n",
    "for prot in ana_obj_dict.keys():\n",
    "    try:\n",
    "        print(prot)\n",
    "        ana_obj = ana_obj_dict[prot][\"autoeq\"]\n",
    "        ana_obj.compute_equilibration_times(compute_missing=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"could not for {prot}\")\n",
    "\n",
    "# check equilibration times\n",
    "eq_dict_avg = {}\n",
    "std_dict_avg = {}\n",
    "sem_dict_avg = {}\n",
    "overall_array = {}\n",
    "for eng in ana_obj_dict[\"tyk2\"][\"autoeq\"].engines:\n",
    "    overall_array[eng] = np.array([])\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "\n",
    "    eq_dict_avg[prot] = {}\n",
    "    std_dict_avg[prot] = {}\n",
    "    sem_dict_avg[prot] = {}\n",
    "\n",
    "    ana_obj = ana_obj_dict[prot][\"autoeq\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # print(eng)\n",
    "        eq_dict_avg[prot][eng] = []\n",
    "        for pert in ana_obj.eq_times_dict[eng].keys():\n",
    "            eq_dict_avg[prot][eng].append(\n",
    "                [\n",
    "                    ana_obj.eq_times_dict[eng][pert][key][\"mean\"]\n",
    "                    for key in ana_obj.eq_times_dict[eng][pert].keys()\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        eq_dict_avg[prot][eng] = np.array(eq_dict_avg[prot][eng])[\n",
    "            np.array(eq_dict_avg[prot][eng]) != None\n",
    "        ]\n",
    "        eq_dict_avg[prot][eng] = eq_dict_avg[prot][eng][\n",
    "            ~np.isnan(list(eq_dict_avg[prot][eng]))\n",
    "        ]\n",
    "        # print(eq_dict_avg[prot][eng])\n",
    "        overall_array[eng] = np.concatenate(\n",
    "            [overall_array[eng], eq_dict_avg[prot][eng]]\n",
    "        )\n",
    "\n",
    "        sem_dict_avg[prot][eng] = _stats.sem(eq_dict_avg[prot][eng])\n",
    "        std_dict_avg[prot][eng] = _stats.tstd(eq_dict_avg[prot][eng])\n",
    "        eq_dict_avg[prot][eng] = np.mean(eq_dict_avg[prot][eng])\n",
    "\n",
    "df = pd.DataFrame.from_dict(eq_dict_avg).transpose() * 100  # transpose for per engine\n",
    "df_sem = (\n",
    "    pd.DataFrame.from_dict(sem_dict_avg).transpose() * 100\n",
    ")  # transpose for per engine\n",
    "df_std = (\n",
    "    pd.DataFrame.from_dict(std_dict_avg).transpose() * 100\n",
    ")  # transpose for per engine\n",
    "print(df)\n",
    "\n",
    "dict_lower = {}\n",
    "dict_higher = {}\n",
    "for eng in ana_obj.engines:\n",
    "    # check normally dist\n",
    "    # if not check_normal_dist(overall_array[eng]):\n",
    "    #     print(\"not normal distribution\")\n",
    "\n",
    "    mean = np.mean(overall_array[eng])\n",
    "    lower_ci, upper_ci = _stats.norm.interval(\n",
    "        confidence=0.95,\n",
    "        loc=np.mean(overall_array[eng]),\n",
    "        scale=_stats.sem(overall_array[eng]),\n",
    "    )\n",
    "    print(eng, mean, lower_ci, upper_ci)\n",
    "    dict_lower[eng] = [lower_ci * 100]\n",
    "    dict_higher[eng] = [upper_ci * 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average for the engines and also per system\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharex=False, sharey=True)\n",
    "\n",
    "# col_dict = pipeline.analysis.set_colours()\n",
    "col_dict = {\n",
    "    \"AMBER22\": \"orange\",\n",
    "    \"SOMD1\": \"darkturquoise\",\n",
    "    \"GROMACS23\": \"orchid\",\n",
    "    \"experimental\": \"midnightblue\",\n",
    "}\n",
    "\n",
    "df_plot = df\n",
    "df_plot.rename(prot_dict_name, inplace=True)\n",
    "df_plot.rename(eng_dict_name, inplace=True, axis=1)\n",
    "\n",
    "# plt.tick_params(axis=\"x\", labelsize=10, rotation=45)\n",
    "# plt.tick_params(axis=\"y\", labelsize=10)\n",
    "\n",
    "df_plot.T.mean().plot.bar(\n",
    "    color=\"purple\",\n",
    "    yerr=df_plot.T.sem(),\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "# plt.tick_params(axis=\"x\", labelsize=10, rotation=45)\n",
    "# plt.tick_params(axis=\"y\", labelsize=10)\n",
    "\n",
    "df_plot.plot.bar(\n",
    "    color=pipeline.analysis.set_colours().values(),\n",
    "    yerr=df_sem,\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "df_plot.mean().plot.bar(\n",
    "    color=col_dict.values(),\n",
    "    yerr=df_plot.sem(),\n",
    "    xlabel=\"MD engine\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    "    ax=axes[2],\n",
    ")\n",
    "plt.tick_params(axis=\"x\", rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = df.set_index(\"protein\")\n",
    "except:\n",
    "    pass\n",
    "# plotting w the bars representing how much of the average is each engine\n",
    "df.div(df.sum(axis=1), axis=0).mul(df.mean(axis=1), axis=0).plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    color=pipeline.analysis.set_colours(),\n",
    "    xlabel=\"protein system\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    ")\n",
    "plt.errorbar(x=df.index, y=df.T.mean(), yerr=df.T.sem(), ecolor=\"black\", linestyle=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of single run uncertainties - same across engines?\n",
    "# can feed into histogram function and also average to compare\n",
    "\n",
    "# abstract histogram plotting so can put in data\n",
    "# abstract other plotting functions so can put in whatever\n",
    "# also need to abstract colour?\n",
    "# histogram\n",
    "all_analysis_object.plot_histogram_sem(pert_val=\"pert\")\n",
    "\n",
    "all_analysis_object.plot_histogram_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dG\n",
    "for prot in ana_obj_dict.keys():\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    ana_obj.plot_scatter_dG()\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        ana_obj.plot_scatter_dG(engines=eng)\n",
    "        ana_obj.lpot_scatter_dG(engines=eng, use_cinnabar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
