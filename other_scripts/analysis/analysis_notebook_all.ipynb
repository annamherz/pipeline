{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis paper\n",
    "# import libraries\n",
    "import sys\n",
    "# sys.path.insert(1, \"/home/anna/Documents/code/python/pipeline\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from scipy.stats import sem as sem\n",
    "import glob\n",
    "import networkx as nx\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "from pipeline import *\n",
    "from pipeline.utils import validate\n",
    "from pipeline.analysis import *\n",
    "\n",
    "print(BSS.__file__)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the analysis method to use\n",
    "ana_dicts = {\"plain\": {\n",
    "    \"estimator\": \"MBAR\",\n",
    "    \"method\": \"alchemlyb\",\n",
    "    \"check overlap\": True,\n",
    "    \"try pickle\": True,\n",
    "    \"save pickle\": True,\n",
    "    \"auto equilibration\": False,\n",
    "    \"statistical inefficiency\": False,\n",
    "    \"truncate lower\": 0,\n",
    "    \"truncate upper\": 100,\n",
    "    \"name\": None,\n",
    "},\n",
    "\"subsampling\": {\n",
    "    \"estimator\": \"MBAR\",\n",
    "    \"method\": \"alchemlyb\",\n",
    "    \"check overlap\": True,\n",
    "    \"try pickle\": True,\n",
    "    \"save pickle\": True,\n",
    "    \"auto equilibration\": False,\n",
    "    \"statistical inefficiency\": True,\n",
    "    \"truncate lower\": 0,\n",
    "    \"truncate upper\": 100,\n",
    "    \"name\": None,\n",
    "},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables\n",
    "\n",
    "# all the options\n",
    "ana_obj_dict = {}\n",
    "\n",
    "for protein in [\"tyk2\",\"mcl1\",\"p38\",\"syk\",\"hif2a\",\"cmet\"]:\n",
    "    ana_obj_dict[protein] = {}\n",
    "\n",
    "    for ana_dict in ana_dicts.items():\n",
    "        ana_prot = analysis_protocol(ana_dict[1])\n",
    "\n",
    "        if protein == \"syk\" or protein == \"cmet\":\n",
    "            main_dir = f\"/backup/{protein}/neutral\"\n",
    "        else:\n",
    "            main_dir = f\"/backup/{protein}\"\n",
    "\n",
    "        bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "\n",
    "        # if need size of protein \n",
    "        try:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.gro\", f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.top\"])[0]\n",
    "        except:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.prm7\", f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.rst7\"])[0]\n",
    "\n",
    "        print(f\"no of residues in the protein: {prot.nResidues()}\")\n",
    "\n",
    "        # choose location for the files\n",
    "        if protein == \"syk\" or protein == \"cmet\" or protein == \"hif2a\":\n",
    "            net_file = f\"{main_dir}/execution_model/network_all.dat\" # the lomap network\n",
    "        else:\n",
    "            net_file = f\"{main_dir}/execution_model/network_lomap.dat\"\n",
    "\n",
    "        exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "        output_folder = f\"{main_dir}/outputs_extracted\"\n",
    "\n",
    "        # prot_file = f\"{main_dir}/execution_model/protocol.dat\" # no protocol used , name added after if needed\n",
    "        pipeline_prot = pipeline_protocol(auto_validate=True)\n",
    "        # pipeline_prot.name(\"\")\n",
    "\n",
    "        # initialise the network object\n",
    "        all_analysis_object = analysis_network(\n",
    "            output_folder,\n",
    "            exp_file=exp_file,\n",
    "            net_file=net_file,\n",
    "            analysis_prot=ana_prot,\n",
    "            method = pipeline_prot.name(), # if the protocol had a name\n",
    "            engines= pipeline_prot.engines(),\n",
    "        )\n",
    "\n",
    "        # compute\n",
    "        all_analysis_object.compute_results()\n",
    "\n",
    "        # add ligands folder\n",
    "        if os.path.isdir(f\"{bench_folder}/inputs/{protein}/ligands\"):\n",
    "            all_analysis_object.add_ligands_folder(f\"{bench_folder}/inputs/{protein}/ligands\")\n",
    "        else:\n",
    "            all_analysis_object.add_ligands_folder(f\"{bench_folder}/inputs/{protein}/ligands_neutral\") \n",
    "        \n",
    "        ana_obj_dict[protein][ana_dict[0]] = all_analysis_object\n",
    "\n",
    "print(ana_obj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgembar\n",
    "engine=\"SOMD\"\n",
    "xml_folder = f\"{ana_obj.results_folder}/edgembar/{engine}/xml_py_files_{analyse.file_ext(ana_obj.analysis_options)}\"\n",
    "print(xml_folder)\n",
    "regular_list = [glob.glob(f) for f in glob.glob(f\"{xml_folder}/*.py\")]\n",
    "print(regular_list)\n",
    "efiles = list(set([item for sublist in regular_list for item in sublist]))\n",
    "\n",
    "g = edgembar.Graph(efiles,\n",
    "                exclude=None,\n",
    "                refnode=None,\n",
    "                ana_obj= ana_obj,\n",
    "                engine=engine)\n",
    "g.Read()\n",
    "g.topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ana_obj = ana_obj_dict[\"p38\"][\"subsampling\"]\n",
    "\n",
    "ana_obj.analyse_mbarnet(compute_missing=False,\n",
    "                        write_xml=False, run_xml_py=False,\n",
    "                        use_experimental=True, overwrite=True,\n",
    "                        solver=\"linear\", engines=[\"SOMD\"],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering the mbarnet analysis\n",
    "prot_res = {}\n",
    "for prot in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "    try:\n",
    "        ana_obj.analyse_mbarnet(compute_missing=False,\n",
    "                                write_xml=True, run_xml_py=True,\n",
    "                                use_experimental=True, overwrite=True,\n",
    "                                solver=\"linear\", engines=[\"SOMD\"],\n",
    "                                )\n",
    "    except:\n",
    "        print(f\"failed for {prot}\")\n",
    "        continue\n",
    "    res_dict = {}\n",
    "    for lig in ana_obj._ligands_dict[\"SOMD\"]:\n",
    "        res_dict[lig] = []\n",
    "    for lig in ana_obj._ligands_dict[\"SOMD\"]:\n",
    "        ana_obj.analyse_mbarnet(compute_missing=False,\n",
    "                                write_xml=False, run_xml_py=False,\n",
    "                                use_experimental=True, overwrite=True,\n",
    "                                solver=\"linear\", engines=[\"SOMD\"],\n",
    "                                refnode=lig\n",
    "                                )\n",
    "        # res_dict\n",
    "        # res = ana_obj._get_stats_mbarnet(\"SOMD\",\"MUE\")\n",
    "        # res_dict[lig] = (res[0][\"SOMD\"][\"experimental\"], res[1][\"SOMD\"][\"experimental\"])\n",
    "        for ligres in ana_obj._mbarnet_computed_DGs[\"SOMD\"]:\n",
    "            res_dict[ligres].append(ana_obj._mbarnet_computed_DGs[\"SOMD\"][ligres][0])\n",
    "            \n",
    "    prot_res[prot] = res_dict\n",
    "\n",
    "# print(res_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "    ana_obj.analyse_mbarnet(compute_missing=False,\n",
    "                        write_xml=False, run_xml_py=False,\n",
    "                        use_experimental=True, overwrite=True,\n",
    "                        solver=\"linear\", engines=[\"SOMD\"],\n",
    "                        refnode=None\n",
    "                        )\n",
    "for prot in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "    res = ana_obj._get_stats_mbarnet(engines=[\"SOMD\"], statistic=\"MUE\")\n",
    "    print(prot, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in ana_obj_dict:\n",
    "    df = pd.DataFrame(res_dict[prot]).T \n",
    "    df[\"mean\"] = df.mean(numeric_only=True, axis=1)\n",
    "    df[\"err\"] = df.sem(numeric_only=True, axis=1)\n",
    "    df_dict = {}\n",
    "    for val,lig in zip(df[\"mean\"], ana_obj.ligands):\n",
    "        df_dict[lig] = val\n",
    "\n",
    "    res = stats_engines.compute_stats(x=[val for val in df_dict.values()],\n",
    "                                y=[val[0] for val in ana_obj.normalised_exper_val_dict.values()], statistic=\"MUE\")\n",
    "    print(prot, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgembar\n",
    "engine = \"SOMD\"\n",
    "xml_folder = f\"{ana_obj.results_folder}/edgembar/{engine}/xml_py_files\" #_{analyse.file_ext(ana_obj.analysis_options)}\"\n",
    "regular_list = [glob.glob(f) for f in glob.glob(f\"{xml_folder}/*.py\")]\n",
    "efiles = list(set([item for sublist in regular_list for item in sublist]))\n",
    "\n",
    "g = edgembar.Graph(efiles,\n",
    "                   exclude=None,\n",
    "                   refnode=None,\n",
    "                   ana_obj=ana_obj,\n",
    "                   engine=engine)\n",
    "g.Read()\n",
    "g.topology.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgedata = [g.GetPathFreeEnergy(g.topology.StrToPath(e.fwdname))\n",
    "            for e in g.entries]\n",
    "for e in edgedata:\n",
    "    print(e.name, e.value, e.error, ana_obj.calc_pert_dict[engine][e.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.GetPathData(\"lig_ejm31~lig_ejm42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ana_obj = ana_obj_dict[\"p38\"][\"plain\"]\n",
    "# function for single dicts\n",
    "ana_obj.compute_other_results(f\"{ana_obj.output_folder}/SOMD_oldsc/results_oldsc/final_summary_SOMD_MBAR_alchemlyb_None_eqfalse_statsfalse_truncate0_100.csv\",\n",
    "                                name=\"SOMD_oldsc\")\n",
    "ana_obj.compute_other_results(f\"{ana_obj.output_folder}/SOMD_newsc/final_summary_SOMD_MBAR_alchemlyb_None_eqfalse_statsfalse_truncate0_100.csv\",\n",
    "                              name=\"SOMD_newsc\")\n",
    "\n",
    "mae = ana_obj.calc_mae_engines(\"pert\", engines=[\"SOMD\", \"SOMD_oldsc\", \"SOMD_newsc\"], recalculate=True)\n",
    "print(mae)\n",
    "mae = ana_obj.calc_spearmans_rank_engines(\n",
    "    \"pert\", engines=[\"SOMD\", \"SOMD_oldsc\", \"SOMD_newsc\"], recalculate=True)\n",
    "print(mae)\n",
    "mae = ana_obj.calc_kendalls_rank_engines(\n",
    "    \"pert\", engines=[\"SOMD\", \"SOMD_oldsc\", \"SOMD_newsc\"], recalculate=True)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pert in ana_obj.calc_pert_dict[\"SOMD_oldsc\"]:\n",
    "    try:\n",
    "        oldsc = abs(ana_obj.calc_pert_dict[\"SOMD_oldsc\"][pert][0] - ana_obj.exper_pert_dict[pert][0])\n",
    "        newsc = abs(ana_obj.calc_pert_dict[\"SOMD_newsc\"][pert][0] - ana_obj.exper_pert_dict[pert][0])\n",
    "        val = \"newsc\" if oldsc > newsc else \"oldsc\"\n",
    "        print(pert, val)\n",
    "        if val == \"oldsc\":\n",
    "            print(\n",
    "                ana_obj.calc_pert_dict[\"SOMD_oldsc\"][pert][0],\n",
    "                ana_obj.calc_pert_dict[\"SOMD_newsc\"][pert][0],\n",
    "                ana_obj.exper_pert_dict[pert][0])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(r2_dict).T\n",
    "df_err = pd.DataFrame(r2_error_dict)\n",
    "df_low = df_err.map(lambda x: x[0])\n",
    "df_high = df_err.map(lambda x: x[1])\n",
    "\n",
    "pal = pipeline.utils.set_colours()\n",
    "pal[\"maximum\"] = \"darkblue\"\n",
    "\n",
    "# # Draw a nested barplot by species and sex\n",
    "g = sns.barplot(\n",
    "    data=df,\n",
    "    # errorbar=\"sd\",\n",
    "    palette=pal,\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"protein system\", \"r2\")\n",
    "g.legend.set_title(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUE for subsampling and plain and autoeq\n",
    "# calculate average MUE for each engine and consensus\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mue_dict = {}\n",
    "mue_err_dict = {}\n",
    "mue_ci_dict = {}\n",
    "\n",
    "mad_dict = {}\n",
    "mad_err_dict = {}\n",
    "mad_ci_dict = {}\n",
    "\n",
    "# TODO joblib or dask (no)\n",
    "# look at embarassingly parallel loops\n",
    "# check how often bootstrapping\n",
    "for prot in ana_obj_dict.keys():\n",
    "    \n",
    "    for name in [\"plain\",\"single\"]:\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        mue_dict[f\"{prot}_{name}\"] = {}\n",
    "        mue_err_dict[f\"{prot}_{name}\"] = {}\n",
    "        mue_ci_dict[f\"{prot}_{name}\"] = {}\n",
    "\n",
    "        mad_dict[f\"{prot}_{name}\"] = {}\n",
    "        mad_err_dict[f\"{prot}_{name}\"] = {}\n",
    "        mad_ci_dict[f\"{prot}_{name}\"] = {}\n",
    "\n",
    "        mad_dict[f\"{prot}_{name}\"] = {}\n",
    "        mad_err_dict[f\"{prot}_{name}\"] = {}\n",
    "        mad_ci_dict[f\"{prot}_{name}\"] = {}\n",
    "        \n",
    "        print(prot, name)\n",
    "        try:\n",
    "            df, df_err, df_ci = ana_obj.calc_mae_engines(pert_val=\"pert\", recalculate=True) # From bootstrapping\n",
    "            for eng in df.columns.values:\n",
    "                mue_dict[f\"{prot}_{name}\"][eng] = df[eng][\"experimental\"]\n",
    "                mue_err_dict[f\"{prot}_{name}\"][eng] = df_err[eng][\"experimental\"]\n",
    "                mue_ci_dict[f\"{prot}_{name}\"][eng] = df_ci[eng][\"experimental\"]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"did not calc mue for {prot}_{name}\")\n",
    "        # try:\n",
    "        #     df, df_err, df_ci = ana_obj.calc_mad_engines(pert_val=\"pert\", recalculate=False) # from bootstrapping\n",
    "        #     mad_dict[f\"{prot}_{name}\"] = df\n",
    "        #     mad_err_dict[f\"{prot}_{name}\"] = df_err # SEM\n",
    "        #     mad_ci_dict[f\"{prot}_{name}\"] = df_ci\n",
    "        # except Exception as e:\n",
    "        #     print(e)\n",
    "        #     print(f\"did not calc mad for {prot}_{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"MUE\")\n",
    "print(mue_dict)\n",
    "print(mue_err_dict)\n",
    "print(mue_ci_dict)\n",
    "\n",
    "#  print(\"MAD\")\n",
    "# print(mad_dict)\n",
    "# print(mad_err_dict)\n",
    "# print(mad_ci_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mad consensus\n",
    "\n",
    "# all systems \n",
    "import itertools as it\n",
    "\n",
    "df = pd.DataFrame(columns=ana_obj.engines, index=ana_obj.engines)\n",
    "df_err = pd.DataFrame(columns=ana_obj.engines, index=ana_obj.engines)\n",
    "df_ci = pd.DataFrame(columns=ana_obj.engines, index=ana_obj.engines)\n",
    "\n",
    "for eng1,eng2 in it.product(ana_obj.engines, ana_obj.engines):\n",
    "        # loc index, column\n",
    "    df.loc[eng2, eng1] = []\n",
    "    # df_err.loc[eng2, eng1] = []\n",
    "    # df_ci.loc[eng2, eng1] = []\n",
    "mae_dict = {}\n",
    "for name in ana_dicts:\n",
    "    mae_list = []\n",
    "    print(name)\n",
    "    for prot in ana_obj_dict.keys(): # \n",
    "        for eng1,eng2 in it.product(ana_obj.engines, ana_obj.engines):\n",
    "            try:\n",
    "                mad_dict[f\"{prot}_{name}\"][eng1][eng2]\n",
    "\n",
    "                # loc index, column\n",
    "                df.loc[eng2, eng1].append(mad_dict[f\"{prot}_{name}\"][eng1][eng2])\n",
    "            # df_err.loc[eng2, eng1].append(mad_err_dict[f\"{prot}_{name}\"][eng1][eng2])\n",
    "            # df_ci.loc[eng2, eng1].append(mad_ci_dict[f\"{prot}_{name}\"][eng1][eng2])\n",
    "            except:\n",
    "                pass\n",
    "# df_mean = df.mean()\n",
    "# df_err = df.std()\n",
    "\n",
    "# print(df_mean)\n",
    "# print(df_err)\n",
    "df\n",
    "# df_ci = \n",
    "# def ci_func\n",
    "# lower_ci,upper_ci = stats.t.interval(0.95, df=self.no_of_repeats-1, \n",
    "#                                             loc=self.freenrg_val, # mean\n",
    "#                                             scale=self.freenrg_err, # SEM\n",
    "#                                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consensus\n",
    "# cycle through each individual engine - view df\n",
    "# mae for subsampling and not subsampling\n",
    "\n",
    "mae_dict = {}\n",
    "for name in [\"plain\",\"single\"]: # ana_dicts\n",
    "    print(name)\n",
    "    me_x_list = []\n",
    "    me_y_list = []\n",
    "    me_x_err_list = []\n",
    "    me_y_err_list = []\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "        ana_obj._initialise_stats_object(check=True)\n",
    "        for eng in [\"AMBER\",\"SOMD\",\"GROMACS\"]:  # ana_obj.engines\n",
    "            x, y, xerr, yerr = ana_obj._stats_object._get_x_y(\"pert\", \"experimental\", eng)\n",
    "            me_x_list.append(x)\n",
    "            me_y_list.append(y)\n",
    "            me_x_err_list.append(xerr)\n",
    "            me_y_err_list.append(yerr)\n",
    "    # print(me_y_list)\n",
    "    me_x_list = pd.concat(me_x_list)\n",
    "    me_y_list = pd.concat(me_y_list)\n",
    "    me_x_err_list = pd.concat(me_x_err_list)\n",
    "    me_y_err_list = pd.concat(me_y_err_list)\n",
    "\n",
    "    values = pipeline.analysis.stats_engines.compute_stats(\n",
    "                                                    x = me_x_list,\n",
    "                                                    y = me_y_list,\n",
    "                                                    xerr = me_x_err_list,\n",
    "                                                    yerr= me_y_err_list,\n",
    "                                                    statistic = \"MUE\")\n",
    "    # (s[\"mle\"], s[\"stderr\"], [s['low'], s['high']])\n",
    "\n",
    "    mae_dict[name] = values\n",
    "    print(values)\n",
    "\n",
    "# mae_dict = {}\n",
    "# for name in ana_dicts:\n",
    "#     mae_list = []\n",
    "#     print(name)\n",
    "#     for prot in ana_obj_dict.keys(): # \n",
    "#         for eng in ana_obj.engines:\n",
    "#             mae_list.append(mue_dict[f\"{prot}_{name}\"][eng])\n",
    "#     mean = np.mean(mae_list)\n",
    "\n",
    "#     # check normally dist\n",
    "#     if len(sem_list) < 50:\n",
    "#         stat, p = stats.shapiro(sem_list)\n",
    "#     else:\n",
    "#         stat, p = stats.kstest(sem_list)\n",
    "#     if p < 0.05:\n",
    "#         pass\n",
    "#     else:\n",
    "#         print(\"not normal distribution\")\n",
    "\n",
    "#     # <30 samples\n",
    "#     lower_ci,upper_ci = stats.t.interval(confidence=0.95, \n",
    "#                     loc=np.mean(mae_list), \n",
    "#                     scale=stats.sem(mae_list)) \n",
    "    \n",
    "#     print(mean, (lower_ci, upper_ci))\n",
    "#     mae_dict[name] = (mean, stats.sem(mae_list),(lower_ci, upper_ci), mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_df = pd.DataFrame.from_dict(sem_dict).dropna().rename(index={\"1ns\": 1, \"2ns\": 2, \"3ns\": 3, \"subsampling\": 4})\n",
    "df = plain_df.map(lambda x: x[0])\n",
    "df_low = plain_df.map(lambda x: x[2][0])\n",
    "df_high = plain_df.map(lambda x: x[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CIs\n",
    "plt.rc(\"font\", size=12)\n",
    "fig, ax = plt.subplots(figsize=[10, 10])\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    col = pipeline.analysis.set_colours()[eng]\n",
    "\n",
    "    ax.plot(df.index, df[eng],\n",
    "            label=eng,\n",
    "            color=col,\n",
    "            )\n",
    "    \n",
    "    ax.fill_between(df.index, df_low[eng], df_high[eng], color=col, alpha=.2)\n",
    "\n",
    "plt.title(\"\", fontsize=20)\n",
    "plt.ylabel(\"Error (kcal/mol)\", fontsize=20)\n",
    "plt.xlabel(\"Simulation time per window (ns)\", fontsize=20)\n",
    "\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig(\n",
    "    f\"/backup/overall_analysis/SEM_w_time_outliers{threshold}removed.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired t-test to see if sig diff\n",
    "stats.ttest_rel(mae_dict[\"1ns\"][3], mae_dict[\"plain\"][3])\n",
    "# if p value less than 0.05  can reject null hypothesis ie the values are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the errors\n",
    "df = pd.DataFrame.from_dict(mue_dict).transpose().dropna()\n",
    "err_df = pd.DataFrame.from_dict(mue_ci_dict).transpose().dropna()\n",
    "df_low = df - err_df.map(lambda x: x[0])\n",
    "df_high = err_df.map(lambda x: x[1]) - df\n",
    "for prot in ana_obj_dict.keys():\n",
    "    df = df.drop([f\"{prot}_plain\"])\n",
    "    err_df = err_df.drop([f\"{prot}_plain\"])\n",
    "    df_low = df_low.drop([f\"{prot}_plain\"])\n",
    "    df_high = df_high.drop([f\"{prot}_plain\"])\n",
    "    df = df.drop([f\"{prot}_1ns\"])\n",
    "    err_df = err_df.drop([f\"{prot}_1ns\"])\n",
    "    df_low = df_low.drop([f\"{prot}_1ns\"])\n",
    "    df_high = df_high.drop([f\"{prot}_1ns\"])\n",
    "    df = df.drop([f\"{prot}_2ns\"])\n",
    "    err_df = err_df.drop([f\"{prot}_2ns\"])\n",
    "    df_low = df_low.drop([f\"{prot}_2ns\"])\n",
    "    df_high = df_high.drop([f\"{prot}_2ns\"])\n",
    "    df = df.drop([f\"{prot}_3ns\"])\n",
    "    err_df = err_df.drop([f\"{prot}_3ns\"])\n",
    "    df_low = df_low.drop([f\"{prot}_3ns\"])\n",
    "    df_high = df_high.drop([f\"{prot}_3ns\"])\n",
    "    df = df.rename({f\"{prot}_subsampling\": f\"{prot.upper()}\"})\n",
    "    err_df = err_df.rename({f\"{prot}_subsampling\":f\"{prot.upper()}\"})\n",
    "    df_high = df_high.rename({f\"{prot}_subsampling\":f\"{prot.upper()}\"})\n",
    "    df_low = df_low.rename({f\"{prot}_subsampling\":f\"{prot.upper()}\"})\n",
    "    df = df.rename(\n",
    "        {f\"{prot}_autoeq\": f\"{prot.upper()}_autoeq\"})\n",
    "    err_df = err_df.rename({f\"{prot}_autoeq\": f\"{prot.upper()}_autoeq\"})\n",
    "    df_high = df_high.rename(\n",
    "        {f\"{prot}_autoeq\": f\"{prot.upper()}_autoeq\"})\n",
    "    df_low = df_low.rename(\n",
    "        {f\"{prot}_autoeq\": f\"{prot.upper()}_autoeq\"})\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    try:\n",
    "        df = df.drop([f\"{prot}_TI\"])\n",
    "        err_df = err_df.drop([f\"{prot}_TI\"])\n",
    "        df_low = df_low.drop([f\"{prot}_TI\"])\n",
    "        df_high = df_high.drop([f\"{prot}_TI\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CIs\n",
    "plt.rc(\"font\", size=12)\n",
    "fig, ax = plt.subplots(figsize=[30,10])\n",
    "\n",
    "width = 0.23\n",
    "placement = [-width * (2 / 2), 0, width * (2 / 2)]\n",
    "placement_dict = {}\n",
    "for eng, place in zip(ana_obj.engines, placement):\n",
    "    placement_dict.update({eng: place})  # for each engine\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    col = pipeline.analysis.set_colours()[eng]\n",
    "    space = placement_dict[eng]\n",
    "\n",
    "    # just always compare to experimental for this\n",
    "    freenrg_df_plotting = df[eng]\n",
    "\n",
    "    # determine positions for X axis labels.\n",
    "    x_locs = np.arange(len(freenrg_df_plotting))\n",
    "\n",
    "    # plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "    ax.bar(\n",
    "        x_locs + space,\n",
    "        height=freenrg_df_plotting,\n",
    "        width=width,\n",
    "        yerr=[df_low[eng], df_high[eng]],\n",
    "        label=eng,\n",
    "        color=col,\n",
    "        )\n",
    "\n",
    "plt.title(\"\", fontsize=20)\n",
    "plt.ylabel(\"MAE (kcal/mol)\", fontsize=20)\n",
    "plt.xlabel(\"Protein(_analysis)\", fontsize=20)\n",
    "\n",
    "plt.xticks(x_locs, freenrg_df_plotting.index, rotation=70, ha=\"right\")\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig(f\"/backup/overall_analysis/MUE_outliers{threshold}removed.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy and precision as a funciton of time\n",
    "# plot the errors\n",
    "df = pd.DataFrame.from_dict(mue_dict).transpose().dropna()\n",
    "err_df = pd.DataFrame.from_dict(mue_ci_dict).transpose().dropna()\n",
    "df_low = df - err_df.map(lambda x: x[0])\n",
    "df_high = err_df.map(lambda x: x[1]) - df\n",
    "for prot in ana_obj_dict.keys():\n",
    "    df = df.drop([f\"{prot}_plain\"])\n",
    "    err_df = err_df.drop([f\"{prot}_plain\"])\n",
    "    df_low = df_low.drop([f\"{prot}_plain\"])\n",
    "    df_high = df_high.drop([f\"{prot}_plain\"])\n",
    "    df = df.drop([f\"{prot}_autoeq\"])\n",
    "    err_df = err_df.drop([f\"{prot}_autoeq\"])\n",
    "    df_low = df_low.drop([f\"{prot}_autoeq\"])\n",
    "    df_high = df_high.drop([f\"{prot}_autoeq\"])\n",
    "    df = df.rename({f\"{prot}_subsampling\": f\"{prot}\"})\n",
    "    err_df = err_df.rename({f\"{prot}_subsampling\": f\"{prot}_4ns\"})\n",
    "    df_high = df_high.rename({f\"{prot}_subsampling\": f\"{prot}_4ns\"})\n",
    "    df_low = df_low.rename({f\"{prot}_subsampling\": f\"{prot}_4ns\"})\n",
    "\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    try:\n",
    "        df = df.drop([f\"{prot}_TI\"])\n",
    "        err_df = err_df.drop([f\"{prot}_TI\"])\n",
    "        df_low = df_low.drop([f\"{prot}_TI\"])\n",
    "        df_high = df_high.drop([f\"{prot}_TI\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle closures\n",
    "\n",
    "cc_dict = {}\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    \n",
    "    for name in ana_dicts:\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        print(prot, name)\n",
    "        ana_obj.compute_cycle_closures()\n",
    "        cc_dict[f\"{prot}_{name}\"] = ana_obj.cycle_dict\n",
    "\n",
    "# plot the cycle closures\n",
    "# plot the errors\n",
    "df = pd.DataFrame.from_dict(cc_dict).transpose()\n",
    "\n",
    "df_ci = df.map(lambda x: x[3])\n",
    "df_mean = df.map(lambda x: x[1]).fillna(0)\n",
    "df_low = df_mean - df_ci.map(lambda x: x[0])\n",
    "df_high = df_ci.map(lambda x: x[1]) - df_mean\n",
    "df_low = df_low.fillna(0)\n",
    "df_high = df_high.fillna(0)\n",
    "df_err = df.map(lambda x: x[2])\n",
    "print(df_mean)\n",
    "print(df_low)\n",
    "print(df_high)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
