{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem as sem\n",
    "import glob\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import itertools as it\n",
    "\n",
    "import pipeline\n",
    "from pipeline.utils import validate\n",
    "from pipeline import *\n",
    "from pipeline.utils import validate\n",
    "from pipeline.analysis import *\n",
    "\n",
    "import cinnabar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the analysis method to use\n",
    "ana_dicts = {\n",
    "    \"plain\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": False,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    # \"subsampling\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": True,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables\n",
    "network = \"combined\"  # lomap rbfenn combined\n",
    "\n",
    "prot_dict_name = {\n",
    "    \"tyk2\": \"TYK2\",\n",
    "    \"mcl1\": \"MCL1\",\n",
    "    \"p38\": \"P38Î±\",\n",
    "    \"syk\": \"SYK\",\n",
    "    \"hif2a\": \"HIF2A\",\n",
    "    \"cmet\": \"CMET\",\n",
    "}\n",
    "eng_dict_name = {\"AMBER\": \"AMBER22\", \"SOMD\": \"SOMD1\", \"GROMACS\": \"GROMACS23\"}\n",
    "\n",
    "# all the options\n",
    "ana_obj_dict = {}\n",
    "\n",
    "for protein in [\"tyk2\", \"mcl1\", \"p38\", \"syk\", \"hif2a\", \"cmet\"]:\n",
    "    ana_obj_dict[protein] = {}\n",
    "\n",
    "    for ana_dict in ana_dicts:\n",
    "        ana_prot = analysis_protocol(ana_dicts[ana_dict])\n",
    "        print(protein, ana_dict)\n",
    "\n",
    "        if protein == \"syk\" or protein == \"cmet\":\n",
    "            main_dir = f\"/backup/{protein}/neutral\"\n",
    "        else:\n",
    "            main_dir = f\"/backup/{protein}\"\n",
    "\n",
    "        bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "\n",
    "        # if need size of protein\n",
    "        try:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.gro\",\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.top\",\n",
    "                ]\n",
    "            )[0]\n",
    "        except:\n",
    "            prot = BSS.IO.readMolecules(\n",
    "                [\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.prm7\",\n",
    "                    f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.rst7\",\n",
    "                ]\n",
    "            )[0]\n",
    "\n",
    "        print(f\"no of residues in the protein: {prot.nResidues()}\")\n",
    "\n",
    "        # choose location for the files\n",
    "        if protein == \"syk\" or protein == \"cmet\" or protein == \"hif2a\":\n",
    "            # the lomap network\n",
    "            net_file = f\"{main_dir}/execution_model/network_all.dat\"\n",
    "        else:\n",
    "            net_file = f\"{main_dir}/execution_model/network_{network}.dat\"\n",
    "\n",
    "        exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "        output_folder = f\"{main_dir}/outputs_extracted\"\n",
    "\n",
    "        # prot_file = f\"{main_dir}/execution_model/protocol.dat\" # no protocol used , name added after if needed\n",
    "        pipeline_prot = pipeline_protocol(auto_validate=True)\n",
    "        # pipeline_prot.name(\"\")\n",
    "\n",
    "        # initialise the network object\n",
    "        all_analysis_object = analysis_network(\n",
    "            output_folder,\n",
    "            exp_file=exp_file,\n",
    "            net_file=net_file,\n",
    "            analysis_prot=ana_prot,\n",
    "            method=pipeline_prot.name(),  # if the protocol had a name\n",
    "            engines=pipeline_prot.engines(),\n",
    "        )\n",
    "\n",
    "        # compute\n",
    "        # all_analysis_object.compute_results()\n",
    "\n",
    "        if ana_dict == \"single\":\n",
    "            all_analysis_object.file_ext = all_analysis_object.file_ext + f\"_{ana_dict}\"\n",
    "\n",
    "        # add ligands folder\n",
    "        if os.path.isdir(f\"{bench_folder}/inputs/{protein}/ligands\"):\n",
    "            all_analysis_object.add_ligands_folder(\n",
    "                f\"{bench_folder}/inputs/{protein}/ligands\"\n",
    "            )\n",
    "        else:\n",
    "            all_analysis_object.add_ligands_folder(\n",
    "                f\"{bench_folder}/inputs/{protein}/ligands_neutral\"\n",
    "            )\n",
    "\n",
    "        ana_obj_dict[protein][ana_dict] = all_analysis_object\n",
    "\n",
    "print(ana_obj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_overlap_dict = {}\n",
    "for prot in ana_obj_dict.keys():\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "    df = ana_obj.perturbing_atoms_and_overlap(read_file=True)\n",
    "    pert_overlap_dict[prot] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the scores\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    ana_obj = ana_obj_dict[prot][\"subsampling\"]\n",
    "\n",
    "    if prot == \"syk\" or prot == \"cmet\":\n",
    "        main_dir = f\"/backup/{prot}/neutral\"\n",
    "    else:\n",
    "        main_dir = f\"/backup/{prot}\"\n",
    "\n",
    "    df = pert_overlap_dict[prot]\n",
    "    df[\"score\"] = np.nan\n",
    "    # read in all the lomap scores\n",
    "    score_dict = {}\n",
    "    # print(f\"{main_dir}/execution_model/network_scores.dat\")\n",
    "    with open(f\"{main_dir}/execution_model/network_scores.dat\") as lfile:\n",
    "        for line in lfile:\n",
    "            score_dict[\n",
    "                f\"{line.split(',')[0].strip()}~{line.split(',')[1].strip()}\"\n",
    "            ] = float(line.split(\",\")[-1].strip())\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"perturbation\"] not in ana_obj.perturbations:\n",
    "            df = df.drop(index)\n",
    "        else:\n",
    "            try:\n",
    "                df.at[index, \"score\"] = score_dict[row[\"perturbation\"]]\n",
    "            except:\n",
    "                try:\n",
    "                    df.at[index, \"score\"] = score_dict[\n",
    "                        f'{row[\"perturbation\"].split(\"~\")[1]}~{row[\"perturbation\"].split(\"~\")[0]}'\n",
    "                    ]\n",
    "                except:\n",
    "                    # print(f\"not {row['perturbation']}\")\n",
    "                    pass\n",
    "\n",
    "    pert_overlap_dict[prot] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write lomap scores for all of the network\n",
    "# pl = pipeline.setup.initialise_pipeline()\n",
    "# # where the ligands for the pipeline are located. These should all be in the same folder in sdf format\n",
    "# pl.ligands_folder(f\"{main_folder}/inputs/{prot}/ligands\")\n",
    "# pl.main_folder(f\"{main_folder}/{prot}_benchmark\")\n",
    "# pl.setup_ligands(file_name=f\"{main_folder}/{prot}_benchmark/execution_model/combined/ligands.dat\")\n",
    "# pl.setup_network(folder=\"combined\")\n",
    "# for pert in pl.perturbations:\n",
    "#     pl.remove_perturbation(pert)\n",
    "# for pert in perturbations:\n",
    "#     pl.add_perturbation(pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "all_df = reduce(\n",
    "    lambda left, right: pd.concat([left, right], axis=0), pert_overlap_dict.values()\n",
    ")\n",
    "df = all_df\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of failed run in terms of perturbing atoms\n",
    "\n",
    "# df_has = df[df[\"percen_overlap_okay\"] >= 0]\n",
    "# df_none = (\n",
    "#     pd.merge(df_has, df, how=\"outer\", indicator=True)\n",
    "#     .query(\"_merge != 'both'\")\n",
    "#     .drop(\"_merge\", axis=1)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# print(len(df_none))\n",
    "# df_none[\"perturbing_atoms\"].plot.hist(bins=10)\n",
    "# plt.xlabel(\"perturbing atoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df  # df.dropna()\n",
    "print(len(df_plot))\n",
    "df_plot.plot.scatter(\n",
    "    \"score\",\n",
    "    \"too_small_avg\",\n",
    "    c=\"diff_to_exp\",\n",
    "    colormap=\"viridis\",\n",
    "    vmin=0,\n",
    "    vmax=5,\n",
    ")\n",
    "# plt.title(f\"\")\n",
    "# plt.xlabel(\"lomap score\")\n",
    "# plt.ylabel(\"average no. of too small off-diagonals per leg\")\n",
    "\n",
    "df_plot.plot.scatter(\n",
    "    \"score\",\n",
    "    \"percen_overlap_okay\",\n",
    "    c=\"diff_to_exp\",\n",
    "    colormap=\"viridis\",\n",
    "    vmin=0,\n",
    "    vmax=5,\n",
    ")\n",
    "# plt.title(f\"\")\n",
    "# plt.xlabel(\"lomap score\")\n",
    "# plt.ylabel(\"percentage of okay overlap\")\n",
    "# )\n",
    "\n",
    "df_plot.plot.scatter(\"score\", \"diff_to_exp\", c=\"too_small_avg\", colormap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as _stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_overlap_dict[\"mcl1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prot in pert_overlap_dict.keys():\n",
    "    df = pert_overlap_dict[prot]\n",
    "    print(prot)\n",
    "    for eng in ana_obj.engines:\n",
    "        df_plot = df.drop(df[df[\"engine\"] != eng].index).reset_index()\n",
    "        small_list = list(df_plot[\"too_small_avg\"].dropna())\n",
    "        lower_ci, upper_ci = _stats.norm.interval(\n",
    "            confidence=0.95, loc=np.mean(small_list), scale=_stats.sem(small_list)\n",
    "        )\n",
    "        print(\n",
    "            f\"{eng}, avg: {np.mean(small_list):.2f}, std: {np.std(small_list):.2f}, 95% CI: {lower_ci:.2f}, {upper_ci:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in ana_obj.engines:\n",
    "    df_plot = df.drop(df[df[\"engine\"] != eng].index).reset_index()\n",
    "    small_list = list(\n",
    "        df_plot[\"diff_to_exp\"].dropna().drop(df_plot[df_plot[\"diff_to_exp\"] > 10].index)\n",
    "    )\n",
    "    lower_ci, upper_ci = _stats.norm.interval(\n",
    "        confidence=0.95, loc=np.mean(small_list), scale=_stats.sem(small_list)\n",
    "    )\n",
    "    print(eng, np.mean(small_list), np.std(small_list), lower_ci, upper_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "\n",
    "for eng, pos in zip(ana_obj.engines, [axes[0], axes[1], axes[2]]):\n",
    "    # plt.clf()\n",
    "    # eng = \"AMBER\"\n",
    "    df_plot = df.drop(df[df[\"engine\"] != eng].index)\n",
    "    print(len(df_plot))\n",
    "\n",
    "    # plt.yscale(\"log\")\n",
    "    plt.scatter(\n",
    "        df_plot[\"score\"],\n",
    "        df_plot[\"too_small_avg\"],\n",
    "        c=df_plot[\"diff_to_exp\"],\n",
    "        vmin=0,\n",
    "        vmax=5,\n",
    "        cmap=\"plasma\",\n",
    "    )\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(\"Difference to experimental\\n value (kcal/mol)\")\n",
    "    plt.ylabel(\"Average number of off-diagonals\\n <0.03 for the perturbation\")\n",
    "    plt.xlabel(\"LOMAP score\")\n",
    "    plt.title(eng_dict_name[eng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in ana_obj.engines:\n",
    "    df_plot = df.drop(df[df[\"engine\"] != eng].index).reset_index()\n",
    "    x = list(\n",
    "        df_plot[\"diff_to_exp\"].dropna().drop(df_plot[df_plot[\"diff_to_exp\"] > 10].index)\n",
    "    )\n",
    "    y = list(\n",
    "        df_plot[\"too_small_avg\"]\n",
    "        .dropna()\n",
    "        .drop(df_plot[df_plot[\"diff_to_exp\"] > 10].index)\n",
    "    )\n",
    "    res = stats_engines.compute_stats(\n",
    "        x=y, y=y, statistic=\"R2\"  # xerr=yerr,  # yerr=yerrexp,\n",
    "    )\n",
    "    print(eng, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.reset_index()\n",
    "df_test = df_plot.drop(df_plot[df_plot[\"diff_to_exp\"] > 5].index)\n",
    "print(df_test[\"too_small_avg\"].mean())\n",
    "print(\n",
    "    len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] != 100].index)),\n",
    "    len(df_test[\"percen_overlap_okay\"]),\n",
    "    100\n",
    "    * len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] != 100].index))\n",
    "    / len(df_test[\"percen_overlap_okay\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for r in range(0, 100, 20):\n",
    "    # for eng in ana_obj.engines:\n",
    "    eng = \"AMBER\"\n",
    "    df_plot = df.drop(df[df[\"engine\"] != eng].index).reset_index()\n",
    "    df_test = df_plot.drop(df_plot[df_plot[\"diff_to_exp\"] > 5].index)\n",
    "    print(eng, df_test[\"too_small_avg\"].mean())\n",
    "    print(\n",
    "        eng,\n",
    "        len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] <= r].index)),\n",
    "        len(df_test[\"percen_overlap_okay\"]),\n",
    "        100\n",
    "        * len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] < r].index))\n",
    "        / len(df_test[\"percen_overlap_okay\"]),\n",
    "    )\n",
    "    x.append(r)\n",
    "    y.append(\n",
    "        100\n",
    "        * len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] < r].index))\n",
    "        / len(df_test[\"percen_overlap_okay\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = []\n",
    "y2 = []\n",
    "for r in range(0, 100, 20):\n",
    "    # for eng in ana_obj.engines:\n",
    "    eng = \"AMBER\"\n",
    "    df_plot = df.drop(df[df[\"engine\"] != eng].index).reset_index()\n",
    "    df_test = df_plot.drop(df_plot[df_plot[\"diff_to_exp\"] < 5].index)\n",
    "    print(eng, df_test[\"too_small_avg\"].mean())\n",
    "    print(\n",
    "        eng,\n",
    "        len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] <= r].index)),\n",
    "        len(df_test[\"percen_overlap_okay\"]),\n",
    "        100\n",
    "        * len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] < r].index))\n",
    "        / len(df_test[\"percen_overlap_okay\"]),\n",
    "    )\n",
    "    x2.append(r)\n",
    "    y2.append(\n",
    "        100\n",
    "        * len(df_test.drop(df_test[df_test[\"percen_overlap_okay\"] < r].index))\n",
    "        / len(df_test[\"percen_overlap_okay\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)  # blue, for more than 5 kcal/mol\n",
    "plt.plot(x2, y2)  # orange, for less than 5 kcal/mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df[[\"diff_to_exp\", \"too_small_avg\"]]\n",
    "x = df_plot.values  # returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_plot = pd.DataFrame(x_scaled, columns=[\"diff_to_exp\", \"too_small_avg\"])\n",
    "\n",
    "r2_score(df_plot[\"diff_to_exp\"].dropna(), df_plot[\"too_small_avg\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df  # .dropna()\n",
    "\n",
    "# plt.xscale(\"log\")\n",
    "# plt.yscale(\"log\")\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\n",
    "    df_plot[\"diff_to_exp\"],\n",
    "    df_plot[\"too_small_avg\"],\n",
    "    c=df_plot[\"score\"],\n",
    ")\n",
    "y_test = list(df_plot[\"diff_to_exp\"].dropna())\n",
    "y_pred = list(df_plot[\"too_small_avg\"].dropna())\n",
    "ax.plot(y_test, LinearRegression().fit(y_test, y_pred).predict(y_test))\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"LOMAP-score\")\n",
    "plt.ylabel(\"Average number of off-diagonals < 0.03\")\n",
    "plt.xlabel(\"Diff to exp\")\n",
    "# these will obviously correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting logarithmically\n",
    "df_plot = df  # .dropna()\n",
    "\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"symlog\")\n",
    "# plt.gca().invert_xaxis()\n",
    "plt.scatter(\n",
    "    df_plot[\"diff_to_exp\"],\n",
    "    df_plot[\"too_small_avg\"],\n",
    "    c=df_plot[\"score\"],\n",
    ")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"score\")\n",
    "plt.ylabel(\"too_small_avg\")\n",
    "plt.xlabel(\"diff_to_exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude outliers as needed\n",
    "df3 = df_plot[df_plot[\"diff_to_exp\"] >= 20]\n",
    "df_out = (\n",
    "    pd.merge(df3, df_plot, how=\"outer\", indicator=True)\n",
    "    .query(\"_merge != 'both'\")\n",
    "    .drop(\"_merge\", axis=1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# df_out = df_plot\n",
    "\n",
    "df_out.plot.scatter(\n",
    "    \"perturbing_atoms\", \"diff_to_exp\", c=\"percen_overlap_okay\", colormap=\"viridis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"perturbing_atoms\", \"percen_overlap_okay\", \"too_small_avg\"]\n",
    "bins = [6, 3, 5]\n",
    "for column, bin in zip(columns, bins):\n",
    "    fig = plt.figure()\n",
    "    df_plot = df[column]\n",
    "    df_plot.plot.hist(subplots=True, bins=bin)\n",
    "    plt.title(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for per engine\n",
    "eng = \"GROMACS\"\n",
    "df2 = df[df[\"engine\"] == eng]\n",
    "df_plot = df2.dropna()\n",
    "df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=\"too_small_avg\", colormap=\"viridis\"\n",
    ")\n",
    "df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"too_small_avg\", c=\"percen_overlap_okay\", colormap=\"viridis\"\n",
    ")\n",
    "df_plot.plot.scatter(\n",
    "    \"percen_overlap_okay\", \"too_small_avg\", c=\"perturbing_atoms\", colormap=\"viridis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = [\"AMBER\", \"SOMD\", \"GROMACS\"]\n",
    "eng_dict = {}\n",
    "\n",
    "col_dict = pipeline.utils.set_colours()\n",
    "\n",
    "for eng in engs:\n",
    "    df2 = df[df[\"engine\"] == eng]\n",
    "    eng_dict[eng] = df2\n",
    "\n",
    "for eng in engs:\n",
    "    df_plot = eng_dict[eng].dropna()\n",
    "    ax = df_plot.plot.scatter(\n",
    "        \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[eng]\n",
    "    )\n",
    "\n",
    "df_plot = eng_dict[\"AMBER\"].dropna()\n",
    "ax1 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[\"AMBER\"]\n",
    ")\n",
    "df_plot = eng_dict[\"SOMD\"].dropna()\n",
    "ax2 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[\"SOMD\"], ax=ax1\n",
    ")\n",
    "df_plot = eng_dict[\"GROMACS\"].dropna()\n",
    "ax3 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[\"GROMACS\"], ax=ax1\n",
    ")\n",
    "plt.legend(col_dict, loc=\"upper right\")\n",
    "print(ax1 == ax2 == ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = [\"AMBER\", \"SOMD\", \"GROMACS\"]\n",
    "eng_dict = {}\n",
    "\n",
    "col_dict = pipeline.utils.set_colours()\n",
    "\n",
    "for eng in engs:\n",
    "    df2 = df[df[\"engine\"] == eng]\n",
    "    df3 = df2[df2[\"diff_to_exp\"] >= 5]\n",
    "    df4 = (\n",
    "        pd.merge(df3, df2, how=\"outer\", indicator=True)\n",
    "        .query(\"_merge != 'both'\")\n",
    "        .drop(\"_merge\", axis=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    eng_dict[eng] = df4\n",
    "\n",
    "for eng in engs:\n",
    "    df_plot = eng_dict[eng].dropna()\n",
    "    ax = df_plot.plot.scatter(\"perturbing_atoms\", \"diff_to_exp\", c=col_dict[eng])\n",
    "\n",
    "df_plot = eng_dict[\"AMBER\"].dropna()\n",
    "ax1 = df_plot.plot.scatter(\"perturbing_atoms\", \"diff_to_exp\", c=col_dict[\"AMBER\"])\n",
    "df_plot = eng_dict[\"SOMD\"].dropna()\n",
    "ax2 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"diff_to_exp\", c=col_dict[\"SOMD\"], ax=ax1\n",
    ")\n",
    "df_plot = eng_dict[\"GROMACS\"].dropna()\n",
    "ax3 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"diff_to_exp\", c=col_dict[\"GROMACS\"], ax=ax1\n",
    ")\n",
    "plt.legend(col_dict, loc=\"upper right\")\n",
    "print(ax1 == ax2 == ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking which perts are bad overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"{main_folder}/extracted/mcl1/perturbing_overlap.dat\"\n",
    "\n",
    "eng_dict_ok = {\"AMBER\": None, \"SOMD\": None, \"GROMACS\": None}\n",
    "eng_dict_not = {\"AMBER\": None, \"SOMD\": None, \"GROMACS\": None}\n",
    "\n",
    "for engine in [\"SOMD\", \"AMBER\", \"GROMACS\"]:\n",
    "    print(engine)\n",
    "    perts_okay = []\n",
    "    perts_not = []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            pert = line.split(\",\")[0].strip()\n",
    "            overlap_okay = line.split(\",\")[3].strip()\n",
    "            eng = line.split(\",\")[1].strip()\n",
    "\n",
    "            if eng == engine:\n",
    "                if overlap_okay == \"100.0\":  #  or overlap_okay == \"50.0\"\n",
    "                    if pert not in perts_okay:\n",
    "                        perts_okay.append(pert)\n",
    "                else:\n",
    "                    if pert not in perts_not:\n",
    "                        perts_not.append(pert)\n",
    "\n",
    "    # for pert in perts_not:\n",
    "    #     if pert in perts_okay:\n",
    "    #         perts_okay.remove(pert)\n",
    "\n",
    "    print(len(perts_okay))\n",
    "    print(perts_okay)\n",
    "    print(len(perts_not))\n",
    "    print(perts_not)\n",
    "    print(\" \")\n",
    "\n",
    "    eng_dict_ok[engine] = perts_okay\n",
    "    eng_dict_not[engine] = perts_not\n",
    "\n",
    "\n",
    "both_perts = []\n",
    "\n",
    "for pert in eng_dict_ok[\"AMBER\"]:\n",
    "    if pert in eng_dict_ok[\"SOMD\"]:\n",
    "        both_perts.append(pert)\n",
    "\n",
    "print(len(both_perts))\n",
    "print(both_perts)\n",
    "print(\" \")\n",
    "\n",
    "all_perts = eng_dict_ok[\"SOMD\"] + eng_dict_not[\"SOMD\"]\n",
    "not_okay = []\n",
    "for pert in all_perts:\n",
    "    if pert not in both_perts:\n",
    "        not_okay.append(pert)\n",
    "\n",
    "print(len(not_okay))\n",
    "print(not_okay)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot = pipeline_protocol()\n",
    "prot.num_lambda(16)\n",
    "pert_dict = {(pert.split(\"~\")[0], pert.split(\"~\")[1]): \"None\" for pert in not_okay}\n",
    "write_network(pert_dict, prot, \"new_mcl1_network_both2.dat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline_annamherz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
