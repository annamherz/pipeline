{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal\">RBFE Network - Analysis</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network provides a basic outline for how to run analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ee6bf532d4c8b826f8abb5ff89df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2023.09.6 jupyter extensions\n",
      "WARNING:root:Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "/home/anna/mambaforge/envs/pipeline/lib/python3.9/site-packages/Bio/Application/__init__.py:40: BiopythonDeprecationWarning: The Bio.Application modules and modules relying on it have been deprecated.\n",
      "\n",
      "Due to the on going maintenance burden of keeping command line application\n",
      "wrappers up to date, we have decided to deprecate and eventually remove these\n",
      "modules.\n",
      "\n",
      "We instead now recommend building your command line and invoking it directly\n",
      "with the subprocess module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "from scipy.stats import sem as sem\n",
    "import sys\n",
    "import glob\n",
    "import networkx as nx\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from pipeline import *\n",
    "from pipeline.utils import validate\n",
    "from pipeline.analysis import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variables need to be set:\n",
    "\n",
    "net_file - the network file that describes all the perturbations that were run and which engine they were run for. Usually generated in the execution_model folder during setup.\n",
    "\n",
    "ana_file - the analysis protocol that was used to analyse the runs. This determines the extension that is used to open the results files. If none is provided, all extensions/analysis methods are considered.\n",
    "\n",
    "exp_file - file containing the experimental results. This can be in yml format (better) or csv. The format of the yml file for each ligand should be:\n",
    "\n",
    "```\n",
    "lig_a:\n",
    "  measurement:\n",
    "    comment:\n",
    "    doi: source of data\n",
    "    error: error\n",
    "    type: ki or ic50\n",
    "    unit: uM or nM \n",
    "    value: value\n",
    "  name: lig_a\n",
    "```\n",
    "\n",
    "results_folder - the location of the results files computed during the analysis stage after the run. The default for this is outputs_extracted/results. \n",
    "\n",
    "output_folder - the location for the graphs and tables generated during this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "protein = \"tyk2\"\n",
    "main_dir = f\"/backup/{protein}\"\n",
    "\n",
    "# choose location for the files\n",
    "net_file = f\"{main_dir}/execution_model/network_combined.dat\"\n",
    "ana_file = f\"{main_dir}/execution_model/analysis_protocol.dat\"\n",
    "exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "output_folder = f\"{main_dir}/outputs_extracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 4652\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    prot = BSS.IO.readMolecules(\n",
    "        [f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.gro\", f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.top\"])[0]\n",
    "except:\n",
    "    prot = BSS.IO.readMolecules(\n",
    "        [f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.rst7\", f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.prm7\"])[0]\n",
    "   \n",
    "\n",
    "print(prot.nResidues(), prot.nAtoms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The protocol from the execution model can also be read in to gain additional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_file = f\"{main_dir}/execution_model/protocol.dat\"\n",
    "pipeline_prot = pipeline_protocol(prot_file, auto_validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can then be initialised into the analysis_network object, which will be used to run the rest of the functions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object = analysis_network(\n",
    "    output_folder,\n",
    "    exp_file=exp_file,\n",
    "    net_file=net_file,\n",
    "    analysis_prot=ana_file,\n",
    "    # method = pipeline_prot.name(), # if the protocol had a name\n",
    "    # method = \"t-test\",\n",
    "    engines= pipeline_prot.engines(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will then analyse the entire network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"/backup/tyk2/outputs_extracted/results/final_summary_SOMD_MBAR_alchemlyb_None_eqfalse_statsfalse_truncate0_100_nottest.csv\"]\n",
    "\n",
    "calc_diff_dict = make_dict.comp_results(\n",
    "                files, all_analysis_object._perturbations_dict[\"SOMD\"], \"SOMD\", method=None\n",
    "            )\n",
    "all_analysis_object.calc_pert_dict[\"SOMD\"] = calc_diff_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df = pd.DataFrame.from_dict(all_analysis_object.calc_pert_dict[\"SOMD\"], orient=\"index\", columns=[\"value\",\"error\"])\n",
    "df = df.reset_index().rename(columns={\"index\":\"perturbations\"})\n",
    "df[\"experimental\"] = df[\"perturbations\"].map({pert:val[0] for pert,val in all_analysis_object.exper_pert_dict.items()})\n",
    "df[\"difference\"] = abs(df[\"experimental\"]-df[\"value\"])\n",
    "df.sort_values(\"difference\", ascending=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.plot_histogram_repeats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ligands folder can be added to visualise any perturbations and draw the network graph of the successful runs. This is generally the folder that was also used at the start for all the ligand inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.add_ligands_folder(\n",
    "    f\"/home/anna/Documents/benchmark/inputs/{protein}/ligands\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can be drawn. The edge colour indicates the error of that leg. Failed runs do not have their edge drawn on default.\n",
    "\n",
    "To visualise the whole network, this can also be drawn seperately as a network object. `networkx_layout_func` can be used as an argument in `graph.draw_graph(networkx_layout_func = nx.circular_layout)` to change the layout of the drawn network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = network_graph(\n",
    "    all_analysis_object.ligands,\n",
    "    all_analysis_object.perturbations,\n",
    "    ligands_folder=all_analysis_object.ligands_folder,\n",
    ")\n",
    "graph.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_analysis_object._initialise_graph_object()\n",
    "all_analysis_object.draw_graph(engines=\"GROMACS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check and visualise any failed perturbations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in all_analysis_object.engines:\n",
    "    print(\n",
    "        f\"failed percentage for {eng}: {100 - all_analysis_object.successful_perturbations(eng)[1]} ({len(all_analysis_object.perturbations) - len(all_analysis_object.successful_perturbations(eng)[2])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in all_analysis_object.engines:\n",
    "    failed_perts = all_analysis_object.failed_perturbations(eng)\n",
    "    print(eng)\n",
    "    for pert in sorted(failed_perts):\n",
    "        print(pert)\n",
    "    # all_analysis_object.draw_failed_perturbations(eng)\n",
    "\n",
    "# all_analysis_object.draw_failed_perturbations(\"SOMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in all_analysis_object.engines:\n",
    "    failed_perts = all_analysis_object.failed_perturbations(eng)\n",
    "    print(eng)\n",
    "    for pert in sorted(failed_perts):\n",
    "        print(pert)\n",
    "    # all_analysis_object.draw_failed_perturbations(eng)\n",
    "\n",
    "# all_analysis_object.draw_failed_perturbations(\"SOMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.exper_pert_dict[\"lig_ejm31~lig_ejm45\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.calc_pert_dict[\"GROMACS\"][\"lig_2u~lig_2x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the failed perturbations have resulted in any disconnected ligands, these can also be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.disconnected_ligands(engine=\"AMBER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cycles can also be considered more closely. The code below gives the average cycle closure for that engine with error. To look at each cycle individually, `all_analysis_object.cycle_dict[engine][0]` has a dictionary of the individual cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.compute_cycle_closures(\"GROMACS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If more extensive analysis has been performed, it is also possible to check for average convergence for the runs. This requires the `analysed_pert.calculate_convergence()` to have been run during the individual analysis for each run. If this was not the case, setting `compute_missing` to `True` in compute_convergence below will cause this to be run. Please note, this can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.compute_convergence(main_dir=main_dir)\n",
    "all_analysis_object.plot_convergence()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different options for plotting. \"pert\" refers to perturbations, so the plotting of the edges, whereas \"lig\" (or \"val\" for values) refers to the ligands, so plotting for each node following the network-wide analysis.\n",
    "\n",
    "The followign plots are available:\n",
    "\n",
    "bar (pert or lig)\n",
    "\n",
    "scatter (pert or lig) - can also be plotted using cinnabar\n",
    "\n",
    "eng vs eng (pert or lig)\n",
    "\n",
    "outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perts = all_analysis_object.get_outliers(threshold=5, name=\"SOMD\")\n",
    "pert_print = (\", \").join(perts)\n",
    "print(pert_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.remove_outliers(threshold=10, name=\"AMBER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.plot_scatter_ddG(engines=\"AMBER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar\n",
    "all_analysis_object.plot_bar_dG()\n",
    "all_analysis_object.plot_bar_ddG()\n",
    "\n",
    "# scatter\n",
    "all_analysis_object.plot_scatter_dG()\n",
    "all_analysis_object.plot_scatter_ddG()\n",
    "all_analysis_object.plot_scatter_dG(use_cinnabar=True)\n",
    "all_analysis_object.plot_scatter_ddG(use_cinnabar=True)\n",
    "\n",
    "for eng in all_analysis_object.engines:\n",
    "    all_analysis_object.plot_scatter_dG(engine=eng)\n",
    "    all_analysis_object.plot_scatter_ddG(engine=eng)\n",
    "\n",
    "    # outliers\n",
    "    all_analysis_object.plot_outliers(engine=eng)\n",
    "    all_analysis_object.plot_outliers(engine=eng, pert_val=\"val\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics of the MAD (comparing engines) and MAE (compared to experimental) can also be computed. The first table shown is the value, and the second table contains the bootstrapped error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = all_analysis_object.calc_mad_engines(pert_val=\"pert\", engines=[\"SOMD\",\"GROMACS\"])\n",
    "# all_analysis_object.calc_mad_engines(pert_val=\"val\")\n",
    "print(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = all_analysis_object.calc_mae_engines(pert_val=\"pert\", engines=\"SOMD\")\n",
    "# all_analysis_object.calc_mad_engines(pert_val=\"val\")\n",
    "print(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ligands can be sorted by binding affinity, and the spearmans rank correlation coefficient calculated (rho)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.sort_ligands_by_binding_affinity(engine=\"GROMACS\")\n",
    "all_analysis_object.sort_ligands_by_experimental_binding_affinity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = all_analysis_object._stats_object.compute_ktau(pert_val=\"val\", y=\"GROMACS\")\n",
    "print(values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other aditional results can be added to the all_analysis_object. These must be in a file similar to that written during the analysis, a csv file with [\"lig_0\", \"lig_1\", \"freenrg\", \"error\", \"engine\", \"analysis\", \"method\"] as the headers. \"engine\", \"analysis\" and \"method\" can be left as None, as the name variable is used for identification of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_name = \"\"\n",
    "other_results_folder = \"\"\n",
    "\n",
    "other_results_files = glob.glob(\n",
    "    f\"{other_results_folder}/freenrg_*_{eng}_MBAR_alchemlyb_None_eqfalse_statsfalse_truncate0end.csv\"\n",
    ")\n",
    "\n",
    "all_analysis_object.compute_other_results(other_results_files, name=other_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in all_analysis_object.engines:\n",
    "    other_results = glob.glob(\n",
    "        f\"{bench_folder}/extracted/{protein}/outputs_extracted/results/final_summary_{eng}_MBAR_alchemlyb_None_eqfalse_statsfalse_truncate0end.csv\"\n",
    "    )\n",
    "    bound_results = glob.glob(\n",
    "        f\"{bench_folder}/extracted/{protein}/outputs_extracted/results/bound_*_{eng}_MBAR_alchemlyb_None_eqfalse_statsfalse_truncate0end.csv\"\n",
    "    )\n",
    "    free_results = glob.glob(\n",
    "        f\"{bench_folder}/extracted/{protein}/outputs_extracted/results/free_*_{eng}_MBAR_alchemlyb_None_eqfalse_statsfalse_truncate0end.csv\"\n",
    "    )\n",
    "    all_analysis_object.compute_other_results(\n",
    "        other_results,\n",
    "        name=f\"prev_{eng}\",\n",
    "        method=None,\n",
    "        bound_files=bound_results,\n",
    "        free_files=free_results,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If required, any perturbations different from those in the considered network can be removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any non main network perturbations\n",
    "for eng in all_analysis_object.other_results_names:\n",
    "    for pert in all_analysis_object._perturbations_dict[eng]:\n",
    "        if pert not in all_analysis_object.perturbations:\n",
    "            all_analysis_object.remove_perturbations(pert, name=eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers can be removed. First, the outliers can be plotted, as in the function earlier, or all outliers over a certain threshold in kcal/mol can be identified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.get_outliers(threshold=5, name=\"GROMACS\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can then be removed, which also automatically recalculates the network values, and the above analysis cells can be rerun for the new visualisation / stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.remove_outliers(threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms of the errors can also be plotted to compare different methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.plot_histogram_legs()\n",
    "all_analysis_object.plot_histogram_repeats()\n",
    "all_analysis_object.plot_histogram_sem(pert_val=\"pert\")\n",
    "all_analysis_object.plot_histogram_sem(pert_val=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also calculate for MBARNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_object.analyse_mbarnet(compute_missing=False, use_experimental=True, write_xml=False, run_xml_py=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dferr = all_analysis_object._get_stats_mbarnet(statistic=\"KTAU\")\n",
    "print(df)\n",
    "print(dferr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosimspace-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
